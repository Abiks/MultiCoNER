{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a990805",
   "metadata": {},
   "source": [
    "# Calculate Perplexity for Russian dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afba01c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:53:25.828777Z",
     "start_time": "2021-11-15T18:53:24.110003Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7caeafe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:53:25.844791Z",
     "start_time": "2021-11-15T18:53:25.832777Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_dataset(filename):\n",
    "    sentences = []\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    id = ''\n",
    "    with open(filename, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            # if line refers to id\n",
    "            line_t = line.replace('\\n', '')\n",
    "            if len(line_t) == 0:\n",
    "                if len(tokens) > 0:\n",
    "                    sentences.append((id, tokens, labels))\n",
    "            # if line is empty\n",
    "            elif line_t[0] == '#':\n",
    "                id = line_t[5:line_t.find('domain') - 1]\n",
    "                tokens = []\n",
    "                labels = []\n",
    "            # if line refers to token and label\n",
    "            else:\n",
    "                token = line_t[:line_t.find('_') - 1]\n",
    "                label = line_t[line_t.rfind('_') + 2:]\n",
    "                tokens.append(token)\n",
    "                labels.append(label)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907f5b65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:53:26.348218Z",
     "start_time": "2021-11-15T18:53:25.850787Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = parse_dataset('data/RU-Russian/ru_train.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d809a478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:53:30.031482Z",
     "start_time": "2021-11-15T18:53:26.352206Z"
    }
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "cnt = Counter()\n",
    "\n",
    "for _, sent, tags in sentences:\n",
    "    tokens = [x.lower() for x in word_tokenize(' '.join(sent))]\n",
    "    for t in tokens:\n",
    "        total += 1\n",
    "        cnt[t] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7a8258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:53:30.046964Z",
     "start_time": "2021-11-15T18:53:30.034951Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity(sent, counter, total):\n",
    "    res = 0\n",
    "    tokens = [x.lower() for x in word_tokenize(' '.join(sent))]\n",
    "    for k in tokens:\n",
    "        if k in counter:\n",
    "            if counter[k] != 0:\n",
    "                res += math.log(counter[k] / total, 2)\n",
    "    return 2 ** (-1 * (res / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ec9aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:53:32.812895Z",
     "start_time": "2021-11-15T18:53:30.052958Z"
    }
   },
   "outputs": [],
   "source": [
    "perplexities = []\n",
    "for _, sent, tags in sentences:\n",
    "    l = calculate_perplexity(sent, cnt, total)\n",
    "    perplexities.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c0b3f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:53:32.827867Z",
     "start_time": "2021-11-15T18:53:32.813865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0005198640820314"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d00d93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:53:32.843580Z",
     "start_time": "2021-11-15T18:53:32.829867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00019489720826440225"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aca840c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:57:32.384582Z",
     "start_time": "2021-11-15T18:57:31.470998Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35a7ce1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:57:46.102192Z",
     "start_time": "2021-11-15T18:57:45.498898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAARRElEQVR4nO3df6zddX3H8edbKjg3pZTWrmmrF2fZYraIeGU1ug2pP0oxlmTYsDgprFsjw2VOEy36x9yvDHCRQWY0jTUrmzqYSmiUbdZCR7akwC2/5IcbFyxpO6AVCtMQjNX3/jifyqHrvfecc8+P7+3n+UhO7vf7+X7P97x7es/rfM7n+znfG5mJJKkOLxl1AZKk4TH0Jakihr4kVcTQl6SKGPqSVJF5oy4AYOHChTk2NjbqMiRpTtm9e/f3M3NRN/dpROiPjY0xMTEx6jIkaU6JiMe6vY/DO5JUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVJFGfCNXvRvb9M2fLe+54rwRViJpLugo9CNiD/AD4CfA4cwcj4gFwPXAGLAHWJeZhyIigGuANcBzwMWZeVf/S9ew+MYiHT+6Gd55e2aekZnjZX0TsCMzVwA7yjrAucCKctsIfK5fxUqSZmc2Y/prga1leStwflv7ddmyC5gfEUtm8TiSpD7pNPQT+FZE7I6IjaVtcWY+XpafABaX5aXA3rb77ittLxIRGyNiIiImDh482EPpkqRudXoi922ZuT8iXgVsj4jvtm/MzIyI7OaBM3MzsBlgfHy8q/tq8NrH8SUdPzrq6Wfm/vLzAHAjcBbw5JFhm/LzQNl9P7C87e7LSpskacRmDP2I+PmIeMWRZeBdwP3ANmB92W09cFNZ3gZcFC0rgWfbhoEkSSPUyfDOYuDG1kxM5gFfzsx/jYg7gRsiYgPwGLCu7H8zremak7SmbF7S96rVlU6mXDqcI9VhxtDPzEeBNxyj/Slg1THaE7isL9VpoAx6qT5ehkGSKmLoS1JFDH1JqogXXDtOTTVe7zi+VDd7+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0JakiTtk8jjgdU9JM7OlLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoiXYZgj2i+xsOeK80ZYiaS5zJ6+JFXE0Jekihj6klQRQ1+SKuKJ3DmoidfN90SzNDcY+upZE998JE3P4R1JqoihL0kVMfQlqSKO6TeYY+aS+q3jnn5EnBARd0fEN8r6aRFxe0RMRsT1EXFiaT+prE+W7WMDql2S1KVuhnf+GHiobf1K4OrMfB1wCNhQ2jcAh0r71WU/SVIDdBT6EbEMOA/4QlkP4Bzgq2WXrcD5ZXltWadsX1X2VyXGNn3zZzdJzdJpT/9vgY8BPy3rpwLPZObhsr4PWFqWlwJ7Acr2Z8v+LxIRGyNiIiImDh482Fv1kqSuzHgiNyLeAxzIzN0RcXa/HjgzNwObAcbHx7Nfx9Vgddt795u6UrN0MnvnrcB7I2IN8DLglcA1wPyImFd688uA/WX//cByYF9EzANOBp7qe+WSpK7NOLyTmZdn5rLMHAMuBG7JzPcDtwIXlN3WAzeV5W1lnbL9lsy0Jy9JDTCbL2d9HPhIREzSGrPfUtq3AKeW9o8Am2ZXoiSpX7r6clZm7gR2luVHgbOOsc/zwPv6UJskqc+8DIMkVcTQl6SKGPqSVBEvuKaRcP6+NBr29CWpIoa+JFXE0Jekihj6klQRT+Rq5DypKw2PPX1JqoihL0kVcXhHQ+Nf0pJGz9BXo0z1xuBYv9Qfhn7D2BuWNEiO6UtSRQx9SaqIoS9JFTH0JakinsjVnOC3dqX+sKcvSRWxp98ATtOUNCz29CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVZMbQj4iXRcQdEXFvRDwQEX9W2k+LiNsjYjIiro+IE0v7SWV9smwfG/C/QZLUoU56+j8CzsnMNwBnAKsjYiVwJXB1Zr4OOARsKPtvAA6V9qvLfpKkBpgx9LPlh2X1peWWwDnAV0v7VuD8sry2rFO2r4qI6FfBkqTedTSmHxEnRMQ9wAFgO/AI8ExmHi677AOWluWlwF6Asv1Z4NRjHHNjRExExMTBgwdn9Y+QJHWmo0srZ+ZPgDMiYj5wI/Ars33gzNwMbAYYHx/P2R5P9fAPqki962r2TmY+A9wKvAWYHxFH3jSWAfvL8n5gOUDZfjLwVD+KlSTNTiezdxaVHj4R8XPAO4GHaIX/BWW39cBNZXlbWadsvyUz7clLUgN0MryzBNgaESfQepO4ITO/EREPAv8UEX8J3A1sKftvAf4hIiaBp4ELB1C3JKkHM4Z+Zt4HvPEY7Y8CZx2j/XngfX2pTpLUV34jV5IqYuhLUkU6mrIpNZXTN6Xu2NOXpIrY0x+R9h6qJA2LPX1Jqog9fR33HPeXXmBPX5IqYuhLUkUc3tFxyRPl0rHZ05ekihj6klQRQ1+SKuKYvo4bjuNLM7OnL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFfEbuaqWf1xFNbKnL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SarIjF/OiojlwHXAYiCBzZl5TUQsAK4HxoA9wLrMPBQRAVwDrAGeAy7OzLsGU77UHf+komrXSU//MPDRzHw9sBK4LCJeD2wCdmTmCmBHWQc4F1hRbhuBz/W9aklST2bs6Wfm48DjZfkHEfEQsBRYC5xddtsK7AQ+Xtqvy8wEdkXE/IhYUo5TNXuZkkatq2vvRMQY8EbgdmBxW5A/QWv4B1pvCHvb7ravtL0o9CNiI61PArz61a/utm6pr7wOj2rRcehHxC8AXwM+nJn/2xq6b8nMjIjs5oEzczOwGWB8fLyr+0qj4puD5rqOQj8iXkor8L+UmV8vzU8eGbaJiCXAgdK+H1jedvdlpU2aExyG0/FsxhO5ZTbOFuChzPxM26ZtwPqyvB64qa39omhZCTzreL4kNUMnPf23Ah8AvhMR95S2TwBXADdExAbgMWBd2XYzremak7SmbF7Sz4IlSb3rZPbOfwAxxeZVx9g/gctmWZckaQD8Rq4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klSRrv6IirrnZXolNYmhL/XIP6iiucjhHUmqiKEvSRVxeGcAHMeX1FT29CWpIvb0pT7wpK7mCnv6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSJO2ZT6zOmbajJ7+pJUEUNfkipi6EtSRQx9SaqIoS9JFXH2jjRAzuRR08zY04+IL0bEgYi4v61tQURsj4iHy89TSntExLURMRkR90XEmYMsXpLUnU6Gd/4eWH1U2yZgR2auAHaUdYBzgRXlthH4XH/KlCT1w4yhn5m3AU8f1bwW2FqWtwLnt7Vfly27gPkRsaRPtUqSZqnXE7mLM/PxsvwEsLgsLwX2tu23r7T9PxGxMSImImLi4MGDPZYhSerGrGfvZGYC2cP9NmfmeGaOL1q0aLZlSJI60GvoP3lk2Kb8PFDa9wPL2/ZbVtokSQ3Qa+hvA9aX5fXATW3tF5VZPCuBZ9uGgSRJIzbjPP2I+ApwNrAwIvYBfwpcAdwQERuAx4B1ZfebgTXAJPAccMkAam4M52BLmmtmDP3M/J0pNq06xr4JXDbboqTjnR0GjYrfyJWGpD3opVHx2juSVBFDX5IqYuhLUkUc05caxBO8GjR7+pJUEXv6feLMDPXK3x0Nkz19SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkX8cpY0B3h5BvWLoS81lN/U1SA4vCNJFTH0JakiDu9Ic4zj+5oNe/qSVBF7+tJxyE8Dmoo9fUmqiD39LjmNTtJcZuhLc5idEHXL4R1JqoihL0kVMfQlqSKO6UvHOadvqp09fUmqiD19qSL2+mXoT8GpcKqVbwzHt4GEfkSsBq4BTgC+kJlXDOJx+sFfcNWqk47NVK+Po+/ra2fu6HvoR8QJwGeBdwL7gDsjYltmPtjvx5I0PIP69GvHa7giM/t7wIi3AJ/KzHeX9csBMvOvp7rP+Ph4TkxM9PR4U/0iTtcrkTR83b4mp3oD6OTTRyftU+lk/9m+UfXrjS4idmfmeFf3GUDoXwCszszfL+sfAH49Mz901H4bgY1l9ZeB/+ryoRYC359luYNibb2xtu41tS6wtl51U9trMnNRNwcf2YnczNwMbO71/hEx0e073LBYW2+srXtNrQusrVeDrm0Q8/T3A8vb1peVNknSiA0i9O8EVkTEaRFxInAhsG0AjyNJ6lLfh3cy83BEfAj4N1pTNr+YmQ/0+3GYxdDQEFhbb6yte02tC6ytVwOtre8nciVJzeW1dySpIoa+JFVkZKEfEV+MiAMRcf8U2yMiro2IyYi4LyLObNu2PiIeLrf1be1viojvlPtcGxFR2hdExPay//aIOKVBtX06Ir5bjnNjRMxvSm1t2z8aERkRC5tSV0T8UXneHoiIq5rynEXEGRGxKyLuiYiJiDhrBLX9VUTsjYgfHnWskyLi+nKs2yNirEG1fSQiHizH2RERr2lKbW3bf7u8DqadTjns2iJiXXnuHoiIL09XGwCZOZIb8JvAmcD9U2xfA/wLEMBK4PbSvgB4tPw8pSyfUrbdUfaNct9zS/tVwKayvAm4skG1vQuYV5avbFJtZdtyWiflHwMWNqEu4O3At4GTyvqrmvKcAd9qW14D7BxBbSuBJcAPjzrWHwKfL8sXAtc3qLa3Ay8vy5c2qbay7RXAbcAuYLwptQErgLvb9pv2tZCZo+vpZ+ZtwNPT7LIWuC5bdgHzI2IJ8G5ge2Y+nZmHgO3A6rLtlZm5K1v/+uuA89uOtbUsb21rH3ltmfmtzDxcjruL1vcaGlFbcTXwMWDaM/5DrutS4IrM/FF57AMNqi2BV5blk4H/GWZt5Zi7MvPxKY515HXwVWDVkU8oo64tM2/NzOfK6tBfB9PVVvwFrU7Z89PVNYLa/gD4bNl/xtcCNHtMfymwt219X2mbrn3fMdoBFrc9YU8AixtUW7vfo9UDaERtEbEW2J+Z986ypr7WBZwO/EYZovj3iHhzg2r7MPDpiNgL/A1w+ZBr6+hYpaPxLHBqQ2prt4Hhvw6mVIZflmdmvy7i1c/n7XTg9Ij4zzKsuHqmB6/uevqZmRHRuHmqEfFJ4DDwpVHXAhARLwc+QWv4qWnm0foIvBJ4M3BDRLy29LpH7VLgTzLzaxGxDtgCvGPENc0ZEfG7wDjwW6OuBSAiXgJ8Brh4xKVMZR6tIZ6zaX06ui0ifi0zn5nqDk3u6U91OYfp2pcdox3gyfLxifJzxo9AQ6yNiLgYeA/w/j4EV79q+yXgNODeiNhT2u+KiF8ccV3Q6gF9vXw8vgP4Ka2LVPWqn7WtB75elv8ZmPZE7gBq6+hYETGP1vDTUw2pjYh4B/BJ4L1Hhu4aUNsrgF8FdpbXwUpg20wnc4dUG7ReC9sy88eZ+T3gv2m9CUzt6EH+Yd6AMaY+2XEeLz7ZcUe+cLLje7ROdJxSlhfksU+urSntn+bFJ3KvalBtq4EHgUVNe96OOu4epjmRO+Tn7IPAn5fl02l9JI6G1PYQcHZZXgXsHvb/Z9t9jz7pdxkvPpF7Q4NqeyPwCLBiVK+DqWo7attOZjiRO+TnbTWwtSwvLK+FU6etrdMnuN834CvA48CPab1bbaD1Yv5g2R60/hjLI8B32p9oWmPfk+V2SVv7OHB/uc/f8cI3jk8FdgAP05r1saBBtU2W/6h7yu3zTantqMfdw/Szd4b5nJ0I/GPZdhdwTlOeM+BtwG7gXuB24E0jqO2qcqyflp+fKu0vo/XpY5LWm9ZrG1Tbt4EneeF1sK0ptR31uDuZefbOMJ+3oDX89GA51oUzZa+XYZCkijR5TF+S1GeGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SarI/wG1eDD+e+QZuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perplexities, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e42a51ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T19:27:23.550567Z",
     "start_time": "2021-11-15T19:27:23.534478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000115420124616"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a097175f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T19:27:32.273681Z",
     "start_time": "2021-11-15T19:27:32.252690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0015770400945676"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d3649",
   "metadata": {},
   "source": [
    "# Translate English to Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f3bb31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:54:13.440946Z",
     "start_time": "2021-11-15T18:54:10.566794Z"
    }
   },
   "outputs": [],
   "source": [
    "from easynmt import EasyNMT\n",
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc102c59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T18:55:31.363260Z",
     "start_time": "2021-11-15T18:54:45.260992Z"
    }
   },
   "outputs": [],
   "source": [
    "translator = EasyNMT('mbart50_en2m')\n",
    "sl = 'en'\n",
    "tl = 'ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24d532fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T21:41:36.111688Z",
     "start_time": "2021-11-15T21:41:36.095701Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocess(t, dict1):\n",
    "    t = t.replace(\"-\",\" \")\n",
    "    t = t.replace(\"&quot;\",\"\\\"\")\n",
    "    t = t.replace(\"&#39;\",\"'\")\n",
    "    t = t.replace(\" DOCSTART \",\"-DOCSTART-\")\n",
    "    for a, b in dict1.items():\n",
    "        t = t.replace(a, b)\n",
    "    t = t.replace(\"â€‹\",\"\")\n",
    "    return t\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    original = ''\n",
    "    tmp = []\n",
    "    string = []\n",
    "    dict1 = {}\n",
    "    n = 0\n",
    "    s=\"\"\n",
    "    v=\"\"\n",
    "    for w in sentence:\n",
    "        original = ' '.join([w[0] for w in sentence])\n",
    "    if original == '':\n",
    "        return None, dict1\n",
    "    for i in range(len(sentence)):\n",
    "        w = sentence[i]\n",
    "        if w[1][:1]==\"B\":\n",
    "            string.append(w[0])\n",
    "        elif w[1][:1]==\"I\":\n",
    "            string.append(w[0])\n",
    "        elif w[1][:1]==\"O\":\n",
    "            tmp.append(w[0])\n",
    "            if len(string) > 0:\n",
    "                s = ' '.join([w for w in string])\n",
    "                string = []\n",
    "        if i == len(sentence) - 1:\n",
    "            if len(string) > 0:\n",
    "                s = ' '.join([w for w in string])\n",
    "                string = []\n",
    "        if s !=\"\":\n",
    "            ner = w[1][2:]\n",
    "            if ner in [\"PER\", \"LOC\", \"CORP\", \"PROD\", \"CW\"]:\n",
    "                s1 = \"[\"+s+\"]\"\n",
    "                new = original.replace(s,s1)\n",
    "                results2 = translator.translate(new, source_lang=sl, target_lang=tl)\n",
    "                t2 = results2\n",
    "                t2 = t2.replace(\"&quot;\",\"\\\"\")\n",
    "                t2 = t2.replace(\"&#39;\",\"'\")\n",
    "                t2 = t2.replace(\"&amp;\",\"&\")\n",
    "                if tl == 'nl':\n",
    "                    pass\n",
    "                else:\n",
    "                    t2 = t2.replace('-',' ')\n",
    "                t2 = word_tokenize(t2)\n",
    "                t2 = ' '.join([w for w in t2])\n",
    "                w1 = t2.split()\n",
    "                l = len(w1)\n",
    "                t3 = \"\"\n",
    "                for i in range(l):\n",
    "                    if w1[i][:1] ==\"[\" and w1[i][-1:] ==\"]\":\n",
    "                        t3 = w1[i]\n",
    "                        break\n",
    "                    elif w1[i][:1] ==\"[\" and w1[i][-1:] !=\"]\":\n",
    "                        t3 = w1[i]\n",
    "                    elif w1[i][:1] !=\"[\" and w1[i][-1:] ==\"]\":\n",
    "                        t3 = t3+\" \"+w1[i]\n",
    "                        break\n",
    "                    else:\n",
    "                        t3 = t3+\" \"+w1[i]\n",
    "                if \"[\" not in t3:\n",
    "                    if ner == \"LOC\":\n",
    "                        s1 = \"[Location] \"+s\n",
    "                    elif ner == \"PER\":\n",
    "                        s1 = \"[Name] \"+s\n",
    "                    elif ner == \"CW\":\n",
    "                        s1 = \"[Creative work] \"+s\n",
    "                    elif ner == \"CORP\":\n",
    "                        s1 = \"[Corporarion] \"+s\n",
    "                    elif ner == \"PROD\":\n",
    "                        s1 = \"[Product] \"+s\n",
    "                    elif ner == \"GRP\":\n",
    "                        s1 = \"[Group] \"+s\n",
    "                    results2 = translator.translate(s1, source_lang=sl, target_lang=tl)\n",
    "                    t2 = results2\n",
    "                    t2 = t2.replace(\"&quot;\",\"\\\"\")\n",
    "                    t2 = t2.replace(\"&#39;\",\"'\")\n",
    "                    t2 = t2.replace(\"&amp;\",\"&\")\n",
    "                    if tl == 'nl':\n",
    "                        pass\n",
    "                    else:\n",
    "                        t2 = t2.replace('-',' ')\n",
    "                    w2 = t2.split()\n",
    "                    l = len(w2)\n",
    "                    t3 = \"\"\n",
    "                    for i in range(l):\n",
    "                        if w2[i][:1] !=\"[\":\n",
    "                            if i == 0:\n",
    "                                t3 = w2[i]\n",
    "                            else:\n",
    "                                t3 = t3 +\" \"+w2[i]\n",
    "                t3 = t3.replace(\"[\",\"\")\n",
    "                t3 = t3.replace(\"]\",\"\")\n",
    "                if n > 9:\n",
    "                    g2 =ner+\"t\"+str(n)\n",
    "                else:\n",
    "                    g2 =ner+str(n)\n",
    "                n=n+1\n",
    "                tmp.append(g2)\n",
    "                keys = []\n",
    "                keys.append(g2)\n",
    "                w2 = t3.split()\n",
    "                l = len(w2)\n",
    "                if l == 1:\n",
    "                    v = \"B-\"+ner+\" \"+w2[0]\n",
    "                elif l > 1:\n",
    "                    for i in range(l):\n",
    "                        if i == 0:\n",
    "                            v = \"B-\"+ner+\" \"+w2[i]\n",
    "                        else:\n",
    "                            v = v+\" \"+\"I-\"+ner+\" \"+w2[i]\n",
    "                values = []\n",
    "                values.append(v)\n",
    "                d1 = dict(zip(keys,values))\n",
    "                if dict1 == {}:\n",
    "                    dict1.update(d1)\n",
    "                elif g2 not in dict1:\n",
    "                    dict1.update(d1)\n",
    "                s=\"\"\n",
    "                string=[]\n",
    "                ner=\"\"\n",
    "                t3=\"\"\n",
    "\n",
    "    return ' '.join([w for w in tmp]), dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcedb577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T21:41:36.650846Z",
     "start_time": "2021-11-15T21:41:36.641848Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(fpath, ofpath):\n",
    "    sentence = []\n",
    "    print(\"Start the process.\")\n",
    "    with open(fpath, 'r', encoding='utf8') as inf, open(ofpath, 'w+', encoding='utf8') as of:\n",
    "        count = 0\n",
    "        deleted = 0\n",
    "        sentence_id = ''\n",
    "        for line in inf:\n",
    "            # if line refers to id\n",
    "            line_t = line.replace('\\n', '')\n",
    "            if len(line_t) == 0:\n",
    "                sentence_preprocessed, dict1 = preprocess(sentence)\n",
    "                if sentence_preprocessed is None:\n",
    "                    continue\n",
    "#                 print(f'original:\\t{sentence_preprocessed}')\n",
    "                results = translator.translate(sentence_preprocessed, source_lang=sl, target_lang=tl)\n",
    "                t = postprocess(results, dict1)\n",
    "                perplex = calculate_perplexity(t, cnt, total)\n",
    "                if perplex >= 1 and perplex <= 1.0016:\n",
    "#                 print(f'translated\\t{t}')\n",
    "                    t_splitted = [x for x in t.split() if len(x) > 0]\n",
    "                    i = 0\n",
    "                    of.write(sentence_id + '\\n')\n",
    "                    while i < len(t_splitted):\n",
    "                        if t_splitted[i][:2] == 'B-' or t_splitted[i][:2] == 'I-':\n",
    "                            of.write(t_splitted[i + 1] + ' _ _ ' + t_splitted[i] + '\\n')\n",
    "                            i += 2\n",
    "                        else:\n",
    "                            of.write(t_splitted[i] + ' _ _ O' + '\\n')\n",
    "                            i += 1\n",
    "                    of.write('\\n')\n",
    "                else:\n",
    "                    deleted += 1\n",
    "                sentence = []\n",
    "                count += 1\n",
    "                if count % 1000 == 0:\n",
    "                    print('-----------------------')\n",
    "                    print(f'{count} sentences done')\n",
    "                    print('-----------------------')\n",
    "            # if line is empty\n",
    "            elif line_t[0] == '#':\n",
    "                sentence_id = line_t[5:line_t.find('domain') - 1]\n",
    "                sentence = []\n",
    "            # if line refers to token and label\n",
    "            else:\n",
    "                token = line_t[:line_t.find('_') - 1]\n",
    "                label = line_t[line_t.rfind('_') + 2:]\n",
    "                sentence.append([token, label])\n",
    "        print(f'{deleted} sentences not included')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccb2d8da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T22:04:38.645922Z",
     "start_time": "2021-11-15T21:41:39.208699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the process.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-131ab37e70cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfpath\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'data/EN-English/en_train.conll'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mofpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/RU-Russian/ru_train_new.conll'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mofpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-caa215b21fe3>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(fpath, ofpath)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mline_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_t\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0msentence_preprocessed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msentence_preprocessed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-10c7152926f3>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0ms1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"[\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mresults2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_lang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m                 \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"&quot;\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\easynmt\\EasyNMT.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, documents, target_lang, source_lang, show_progress_bar, beam_size, batch_size, perform_sentence_splitting, paragraph_split, sentence_splitter, document_language_detection, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;31m#logger.info(\"Translate {} sentences\".format(len(splitted_sentences)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0mtranslated_sentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplitted_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_lang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_lang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource_lang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;31m# Merge sentences back to documents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\easynmt\\EasyNMT.py\u001b[0m in \u001b[0;36mtranslate_sentences\u001b[1;34m(self, sentences, target_lang, source_lang, show_progress_bar, beam_size, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m                 \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences_sorted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_lang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource_lang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_lang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;31m#Restore original sorting of sentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\easynmt\\models\\AutoModel.py\u001b[0m in \u001b[0;36mtranslate_sentences\u001b[1;34m(self, sentences, source_lang, target_lang, device, beam_size, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lang_code_to_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'forced_bos_token_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang_code_to_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_lang\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mtranslated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, **model_kwargs)\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             )\n\u001b[1;32m-> 1056\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1057\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   1733\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\models\\mbart\\modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1303\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         )\n\u001b[1;32m-> 1305\u001b[1;33m         \u001b[0mlm_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amina\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fpath ='data/EN-English/en_train.conll'\n",
    "ofpath = 'data/RU-Russian/ru_train_new.conll'\n",
    "run(fpath, ofpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90876026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
