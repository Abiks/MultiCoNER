{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f3bb31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T17:20:04.366548Z",
     "start_time": "2021-11-24T17:20:03.015862Z"
    }
   },
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc102c59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T17:20:04.396836Z",
     "start_time": "2021-11-24T17:20:04.368551Z"
    }
   },
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "sl = 'en'\n",
    "tl = 'ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d532fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T17:20:04.428625Z",
     "start_time": "2021-11-24T17:20:04.398817Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocess(t, dict1):\n",
    "    tags = [\"PER\", \"LOC\", \"CORP\", \"PROD\", \"CW\", \"GRP\"]\n",
    "    t = t.replace(\"-\",\" \")\n",
    "    t = t.replace(\"&quot;\",\"\\\"\")\n",
    "    t = t.replace(\"&#39;\",\"'\")\n",
    "    t = t.replace(\" DOCSTART \",\"-DOCSTART-\")\n",
    "    t = t.replace(\"per\", \"PER\")\n",
    "    for tag in tags:\n",
    "        t = t.replace(tag, ' ' + tag)\n",
    "    for a, b in dict1.items():\n",
    "        t = t.replace(a, b)\n",
    "    t = t.replace(\"â€‹\",\"\")\n",
    "    return t\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    original = ''\n",
    "    tmp = []\n",
    "    string = []\n",
    "    dict1 = {}\n",
    "    n = 0\n",
    "    s=\"\"\n",
    "    v=\"\"\n",
    "    ner = ''\n",
    "    for w in sentence:\n",
    "        original = ' '.join([w[0] for w in sentence])\n",
    "    if original == '':\n",
    "        return None, dict1\n",
    "    for i in range(len(sentence)):\n",
    "        w = sentence[i]\n",
    "        if w[1][:1]==\"B\":\n",
    "            string.append(w[0])\n",
    "            ner = w[1][2:]\n",
    "        elif w[1][:1]==\"I\":\n",
    "            string.append(w[0])\n",
    "            ner = w[1][2:]\n",
    "        elif w[1][:1]==\"O\":\n",
    "            tmp.append(w[0])\n",
    "            if len(string) > 0:\n",
    "                s = ' '.join([w for w in string])\n",
    "                string = []\n",
    "        if i == len(sentence) - 1:\n",
    "            if len(string) > 0:\n",
    "                s = ' '.join([w for w in string])\n",
    "                string = []\n",
    "        if s != '':\n",
    "            if ner in [\"PER\", \"LOC\", \"CORP\", \"PROD\", \"CW\", \"GRP\"]:\n",
    "                s1 = \"[\"+s+\"]\"\n",
    "                new = original.replace(s,s1)\n",
    "                results2 = translator.translate(new, src=sl, dest=tl).text\n",
    "                t2 = results2\n",
    "                t2 = t2.replace(\"&quot;\",\"\\\"\")\n",
    "                t2 = t2.replace(\"&#39;\",\"'\")\n",
    "                t2 = t2.replace(\"&amp;\",\"&\")\n",
    "                if tl == 'nl':\n",
    "                    pass\n",
    "                else:\n",
    "                    t2 = t2.replace('-',' ')\n",
    "                t2 = word_tokenize(t2)\n",
    "                t2 = ' '.join([w for w in t2])\n",
    "                w1 = t2.split()\n",
    "                l = len(w1)\n",
    "                t3 = \"\"\n",
    "                for i in range(l):\n",
    "                    if w1[i][:1] ==\"[\" and w1[i][-1:] ==\"]\":\n",
    "                        t3 = w1[i]\n",
    "                        break\n",
    "                    elif w1[i][:1] ==\"[\" and w1[i][-1:] !=\"]\":\n",
    "                        t3 = w1[i]\n",
    "                    elif w1[i][:1] !=\"[\" and w1[i][-1:] ==\"]\":\n",
    "                        t3 = t3+\" \"+w1[i]\n",
    "                        break\n",
    "                    else:\n",
    "                        t3 = t3+\" \"+w1[i]\n",
    "                if \"[\" not in t3:\n",
    "                    if ner == \"LOC\":\n",
    "                        s1 = \"[Location] \"+s\n",
    "                    elif ner == \"PER\":\n",
    "                        s1 = \"[Name] \"+s\n",
    "                    elif ner == \"CW\":\n",
    "                        s1 = \"[Creative work] \"+s\n",
    "                    elif ner == \"CORP\":\n",
    "                        s1 = \"[Corporarion] \"+s\n",
    "                    elif ner == \"PROD\":\n",
    "                        s1 = \"[Product] \"+s\n",
    "                    elif ner == \"GRP\":\n",
    "                        s1 = \"[Group] \"+s\n",
    "                    results2 = translator.translate(s1, src=sl, dest=tl).text\n",
    "                    t2 = results2\n",
    "                    t2 = t2.replace(\"&quot;\",\"\\\"\")\n",
    "                    t2 = t2.replace(\"&#39;\",\"'\")\n",
    "                    t2 = t2.replace(\"&amp;\",\"&\")\n",
    "                    if tl == 'nl':\n",
    "                        pass\n",
    "                    else:\n",
    "                        t2 = t2.replace('-',' ')\n",
    "                    w2 = t2.split()\n",
    "                    l = len(w2)\n",
    "                    t3 = \"\"\n",
    "                    for i in range(l):\n",
    "                        if w2[i][:1] !=\"[\":\n",
    "                            if i == 0:\n",
    "                                t3 = w2[i]\n",
    "                            else:\n",
    "                                t3 = t3 +\" \"+w2[i]\n",
    "                t3 = t3.replace(\"[\",\"\")\n",
    "                t3 = t3.replace(\"]\",\"\")\n",
    "                if n > 9:\n",
    "                    g2 =ner+\"t\"+str(n)\n",
    "                else:\n",
    "                    g2 =ner+str(n)\n",
    "                n=n+1\n",
    "                tmp.append(g2)\n",
    "                keys = []\n",
    "                keys.append(g2)\n",
    "                w2 = t3.split()\n",
    "                l = len(w2)\n",
    "                if l == 1:\n",
    "                    v = \"B-\"+ner+\" \"+w2[0]\n",
    "                elif l > 1:\n",
    "                    for i in range(l):\n",
    "                        if i == 0:\n",
    "                            v = \"B-\"+ner+\" \"+w2[i]\n",
    "                        else:\n",
    "                            v = v+\" \"+\"I-\"+ner+\" \"+w2[i]\n",
    "                values = []\n",
    "                values.append(v)\n",
    "                d1 = dict(zip(keys,values))\n",
    "                if dict1 == {}:\n",
    "                    dict1.update(d1)\n",
    "                elif g2 not in dict1:\n",
    "                    dict1.update(d1)\n",
    "                s=\"\"\n",
    "                string=[]\n",
    "                ner=\"\"\n",
    "                t3=\"\"\n",
    "\n",
    "    return ' '.join([w for w in tmp]), dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcedb577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T17:20:04.444428Z",
     "start_time": "2021-11-24T17:20:04.431433Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(fpath, ofpath):\n",
    "    sentence = []\n",
    "    print(\"Start the process.\")\n",
    "    with open(fpath, 'r', encoding='utf8') as inf, open(ofpath, 'w+', encoding='utf8') as of:\n",
    "        count = 0\n",
    "        deleted = 0\n",
    "        sentence_id = ''\n",
    "        for line in inf:\n",
    "            # if line refers to id\n",
    "            line_t = line.replace('\\n', '')\n",
    "            if len(line_t) == 0:\n",
    "#                 print(f'Original: {sentence}')\n",
    "                sentence_preprocessed, dict1 = preprocess(sentence)\n",
    "                if sentence_preprocessed is None:\n",
    "                    continue\n",
    "#                 print(f'Preprocessed: {sentence_preprocessed}')\n",
    "                results = translator.translate(sentence_preprocessed, src=sl, dest=tl).text\n",
    "                t = postprocess(results, dict1)\n",
    "#                 print(f'Result: {t}')\n",
    "#                 print(' ')\n",
    "                t_splitted = [x for x in t.split() if len(x) > 0]\n",
    "                i = 0\n",
    "                of.write('#' + sentence_id + '\\n')\n",
    "                while i < len(t_splitted):\n",
    "                    if t_splitted[i][:2] == 'B-' or t_splitted[i][:2] == 'I-':\n",
    "                        of.write(t_splitted[i + 1] + ' _ _ ' + t_splitted[i] + '\\n')\n",
    "                        i += 2\n",
    "                    else:\n",
    "                        of.write(t_splitted[i] + ' _ _ O' + '\\n')\n",
    "                        i += 1\n",
    "                of.write('\\n')\n",
    "                sentence = []\n",
    "                count += 1\n",
    "                if count % 1000 == 0:\n",
    "                    print('-----------------------')\n",
    "                    print(f'{count} sentences done')\n",
    "                    print('-----------------------')\n",
    "            # if line is empty\n",
    "            elif line_t[0] == '#':\n",
    "                sentence_id = line_t[5:line_t.find('domain') - 1]\n",
    "                sentence = []\n",
    "            # if line refers to token and label\n",
    "            else:\n",
    "                token = line_t[:line_t.find('_') - 1]\n",
    "                label = line_t[line_t.rfind('_') + 2:]\n",
    "                sentence.append([token, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2d8da",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-24T17:20:03.023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the process.\n",
      "-----------------------\n",
      "1000 sentences done\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "fpath ='data/EN-English/en_train.conll'\n",
    "ofpath = 'data/RU-Russian/ru_train_new.conll'\n",
    "run(fpath, ofpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43b224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
