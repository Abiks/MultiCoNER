{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "central-evidence",
   "metadata": {},
   "source": [
    "# Читаем обучающий датасет и делаем стратифицированное разбиение\n",
    "\n",
    "\n",
    "dev датасет составляет примерно 5% от трейна. \n",
    "\n",
    "Для валидации отпилю 15% выборки, должно хватить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ordinary-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assumed-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(17)\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incident-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../data/train_dataset.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-forth",
   "metadata": {},
   "source": [
    "Копипаста с ноутбука с EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quantitative-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def count_entities(sample):\n",
    "    collapsed_entities = []\n",
    "    saw_begin_before = False\n",
    "\n",
    "    for label in sample['token_labels']:\n",
    "        if label == 'O':\n",
    "            saw_begin_before = False\n",
    "        elif label[0] == 'B':\n",
    "            saw_begin_before = True\n",
    "            collapsed_entities.append(label[2:])\n",
    "        elif label[0] == 'I':\n",
    "            if saw_begin_before:\n",
    "                continue\n",
    "            else:\n",
    "                raise ValueError(\"Found I-label without B-label before\")\n",
    "    \n",
    "    c = dict(Counter(collapsed_entities))\n",
    "    c['lang'] = sample['lang']\n",
    "    return c\n",
    "\n",
    "\n",
    "entity_counts = pd.DataFrame(\n",
    "    [count_entities(sample) for sample in data]\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-spelling",
   "metadata": {},
   "source": [
    "Бить будем по текстам, а не по сущностям. Поэтому нам нужно привести все счетчики сущностей к бинарному виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minute-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_names = ['GRP', 'PER', 'CW', 'PROD', 'CORP', 'LOC']\n",
    "\n",
    "entity_counts[entity_names] = (entity_counts[entity_names] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "short-midnight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORP</th>\n",
       "      <th>lang</th>\n",
       "      <th>GRP</th>\n",
       "      <th>PER</th>\n",
       "      <th>CW</th>\n",
       "      <th>PROD</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BN-Bangla</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>BN-Bangla</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>BN-Bangla</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>BN-Bangla</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>BN-Bangla</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CORP       lang  GRP  PER  CW  PROD  LOC\n",
       "0     1  BN-Bangla    0    0   0     0    0\n",
       "1     0  BN-Bangla    1    0   0     0    0\n",
       "2     0  BN-Bangla    0    1   0     0    0\n",
       "3     1  BN-Bangla    0    0   0     0    0\n",
       "4     0  BN-Bangla    1    0   0     0    0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-textbook",
   "metadata": {},
   "source": [
    "Стратицифированное разбиение из sklearn работает с одним столбцом \"целевая переменная\". Нам это не подходит, сделаю свою реализацию. \n",
    "\n",
    "\n",
    "Идеально провести разбиение, судя по всему, не получится, поэтому сделаем \"перекос\" максимально близким к тому, что наблюдается в train/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indirect-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "langmeans_diffs = pd.read_csv('../data/processed_data/langmeans_diffs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "median-maldives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>CORP</th>\n",
       "      <th>GRP</th>\n",
       "      <th>PER</th>\n",
       "      <th>CW</th>\n",
       "      <th>PROD</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BN-Bangla</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.029134</td>\n",
       "      <td>0.027149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE-German</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.024020</td>\n",
       "      <td>0.023595</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.033440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN-English</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.024747</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.018039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES-Spanish</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.028456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FA-Farsi</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>0.012296</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.014788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lang      CORP       GRP       PER        CW      PROD       LOC\n",
       "0   BN-Bangla  0.010989  0.009690  0.009673  0.009020  0.029134  0.027149\n",
       "1   DE-German  0.008701  0.024020  0.023595  0.004469  0.023954  0.033440\n",
       "2  EN-English  0.033113  0.000948  0.002688  0.024747  0.003913  0.018039\n",
       "3  ES-Spanish  0.006446  0.003276  0.004322  0.000441  0.003358  0.028456\n",
       "4    FA-Farsi  0.002247  0.000531  0.019951  0.012296  0.004739  0.014788"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langmeans_diffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dress-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = entity_counts['lang'].unique()\n",
    "\n",
    "\n",
    "val_indices = []\n",
    "\n",
    "for lang in langs:  # работаем с каждым языком по отдельности\n",
    "    \n",
    "    # частоты у сущностей, добавляемых первыми, искажаются сильнее\n",
    "    # поэтому мы начинаем с наиболее \"искаженных\" сущностей для данного языка\n",
    "    entity_names = langmeans_diffs.loc[langmeans_diffs['lang'] == lang, entity_names].T.iloc[:,0].sort_values(ascending=False).index.tolist()\n",
    "    \n",
    "    \n",
    "    for entity in entity_names:  # и для каждой сущности\n",
    "        total = entity_counts.loc[entity_counts['lang'] == lang, entity].sum()\n",
    "        quota = int(total * 0.15)  # сколько всего текстов нужно отложить в валидацию\n",
    "        already_added = entity_counts.loc[(entity_counts['lang'] == lang) & entity_counts.index.isin(val_indices), entity].sum()  # сколько текстов из уже добавленных в валидацию содержат эту сущность\n",
    "        to_add = quota - already_added\n",
    "        \n",
    "        # Наблюдается проблема: из-за того, что в одном тексте могут быть несколько сущностей разного вида,\n",
    "        # мы получаем сильное искажение соотношений для тех сущностей, которые мы добавили в начале. \n",
    "        # Чтобы ее сгладить, мы будем понижать вероятность взять в валидацию те тексты, в которых много сущностей разного вида. \n",
    "        # Просто линейно \n",
    "        \n",
    "        probabilities = 1 / entity_counts.loc[(entity_counts['lang'] == lang) & (entity_counts[entity] == 1), entity_names].sum(axis=1)\n",
    "        probabilities /= probabilities.sum()\n",
    "        \n",
    "        \n",
    "        new_val_indices = np.random.choice(entity_counts.loc[(entity_counts['lang'] == lang) & (entity_counts[entity] == 1)].index, to_add, replace=False, p=probabilities)\n",
    "        val_indices.extend(new_val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-booth",
   "metadata": {},
   "source": [
    "Проверяем корректность разбиения. Аналогично EDA (сейчас опять будет копипаста кода), убеждаемся, что по всем языкам и по всем сущностям мы сохранили их соотношение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excessive-danish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>PROD</th>\n",
       "      <th>CW</th>\n",
       "      <th>GRP</th>\n",
       "      <th>CORP</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">BN-Bangla</th>\n",
       "      <th>train</th>\n",
       "      <td>0.153367</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.140990</td>\n",
       "      <td>0.157211</td>\n",
       "      <td>0.169742</td>\n",
       "      <td>0.170357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.153578</td>\n",
       "      <td>0.208551</td>\n",
       "      <td>0.140925</td>\n",
       "      <td>0.157068</td>\n",
       "      <td>0.169721</td>\n",
       "      <td>0.170157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DE-German</th>\n",
       "      <th>train</th>\n",
       "      <td>0.201247</td>\n",
       "      <td>0.170082</td>\n",
       "      <td>0.202805</td>\n",
       "      <td>0.196182</td>\n",
       "      <td>0.184106</td>\n",
       "      <td>0.253292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.210953</td>\n",
       "      <td>0.163083</td>\n",
       "      <td>0.180933</td>\n",
       "      <td>0.213793</td>\n",
       "      <td>0.174442</td>\n",
       "      <td>0.272617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">EN-English</th>\n",
       "      <th>train</th>\n",
       "      <td>0.207079</td>\n",
       "      <td>0.166783</td>\n",
       "      <td>0.203890</td>\n",
       "      <td>0.207079</td>\n",
       "      <td>0.179463</td>\n",
       "      <td>0.260132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.213088</td>\n",
       "      <td>0.156646</td>\n",
       "      <td>0.232720</td>\n",
       "      <td>0.188139</td>\n",
       "      <td>0.202454</td>\n",
       "      <td>0.250307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ES-Spanish</th>\n",
       "      <th>train</th>\n",
       "      <td>0.212638</td>\n",
       "      <td>0.171498</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0.194016</td>\n",
       "      <td>0.168926</td>\n",
       "      <td>0.240299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.229116</td>\n",
       "      <td>0.159773</td>\n",
       "      <td>0.194242</td>\n",
       "      <td>0.181671</td>\n",
       "      <td>0.176805</td>\n",
       "      <td>0.257502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">FA-Farsi</th>\n",
       "      <th>train</th>\n",
       "      <td>0.215679</td>\n",
       "      <td>0.171393</td>\n",
       "      <td>0.199984</td>\n",
       "      <td>0.182892</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.221195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.164265</td>\n",
       "      <td>0.193495</td>\n",
       "      <td>0.169205</td>\n",
       "      <td>0.168794</td>\n",
       "      <td>0.260601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HI-Hindi</th>\n",
       "      <th>train</th>\n",
       "      <td>0.158867</td>\n",
       "      <td>0.199046</td>\n",
       "      <td>0.147706</td>\n",
       "      <td>0.184960</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.155711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.157279</td>\n",
       "      <td>0.199740</td>\n",
       "      <td>0.146880</td>\n",
       "      <td>0.181976</td>\n",
       "      <td>0.176776</td>\n",
       "      <td>0.158579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">KO-Korean</th>\n",
       "      <th>train</th>\n",
       "      <td>0.237508</td>\n",
       "      <td>0.162477</td>\n",
       "      <td>0.229388</td>\n",
       "      <td>0.195971</td>\n",
       "      <td>0.193941</td>\n",
       "      <td>0.228061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.245185</td>\n",
       "      <td>0.170144</td>\n",
       "      <td>0.204655</td>\n",
       "      <td>0.174960</td>\n",
       "      <td>0.195024</td>\n",
       "      <td>0.250803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NL-Dutch</th>\n",
       "      <th>train</th>\n",
       "      <td>0.233038</td>\n",
       "      <td>0.169468</td>\n",
       "      <td>0.188220</td>\n",
       "      <td>0.192733</td>\n",
       "      <td>0.165577</td>\n",
       "      <td>0.229381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.219363</td>\n",
       "      <td>0.165441</td>\n",
       "      <td>0.207516</td>\n",
       "      <td>0.176062</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.232843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RU-Russian</th>\n",
       "      <th>train</th>\n",
       "      <td>0.210204</td>\n",
       "      <td>0.166783</td>\n",
       "      <td>0.187873</td>\n",
       "      <td>0.181670</td>\n",
       "      <td>0.171358</td>\n",
       "      <td>0.219974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.195589</td>\n",
       "      <td>0.163962</td>\n",
       "      <td>0.204328</td>\n",
       "      <td>0.183521</td>\n",
       "      <td>0.181856</td>\n",
       "      <td>0.209738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TR-Turkish</th>\n",
       "      <th>train</th>\n",
       "      <td>0.217998</td>\n",
       "      <td>0.174834</td>\n",
       "      <td>0.201870</td>\n",
       "      <td>0.189716</td>\n",
       "      <td>0.164862</td>\n",
       "      <td>0.233580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.228398</td>\n",
       "      <td>0.163083</td>\n",
       "      <td>0.202840</td>\n",
       "      <td>0.199594</td>\n",
       "      <td>0.167546</td>\n",
       "      <td>0.210142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ZH-Chinese</th>\n",
       "      <th>train</th>\n",
       "      <td>0.295387</td>\n",
       "      <td>0.275206</td>\n",
       "      <td>0.288063</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.226664</td>\n",
       "      <td>0.115864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.299270</td>\n",
       "      <td>0.267640</td>\n",
       "      <td>0.310219</td>\n",
       "      <td>0.040146</td>\n",
       "      <td>0.210868</td>\n",
       "      <td>0.100973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            LOC      PROD        CW       GRP      CORP  \\\n",
       "lang       type                                                           \n",
       "BN-Bangla  train       0.153367  0.208333  0.140990  0.157211  0.169742   \n",
       "           validation  0.153578  0.208551  0.140925  0.157068  0.169721   \n",
       "DE-German  train       0.201247  0.170082  0.202805  0.196182  0.184106   \n",
       "           validation  0.210953  0.163083  0.180933  0.213793  0.174442   \n",
       "EN-English train       0.207079  0.166783  0.203890  0.207079  0.179463   \n",
       "           validation  0.213088  0.156646  0.232720  0.188139  0.202454   \n",
       "ES-Spanish train       0.212638  0.171498  0.216534  0.194016  0.168926   \n",
       "           validation  0.229116  0.159773  0.194242  0.181671  0.176805   \n",
       "FA-Farsi   train       0.215679  0.171393  0.199984  0.182892  0.180328   \n",
       "           validation  0.228489  0.164265  0.193495  0.169205  0.168794   \n",
       "HI-Hindi   train       0.158867  0.199046  0.147706  0.184960  0.175493   \n",
       "           validation  0.157279  0.199740  0.146880  0.181976  0.176776   \n",
       "KO-Korean  train       0.237508  0.162477  0.229388  0.195971  0.193941   \n",
       "           validation  0.245185  0.170144  0.204655  0.174960  0.195024   \n",
       "NL-Dutch   train       0.233038  0.169468  0.188220  0.192733  0.165577   \n",
       "           validation  0.219363  0.165441  0.207516  0.176062  0.180556   \n",
       "RU-Russian train       0.210204  0.166783  0.187873  0.181670  0.171358   \n",
       "           validation  0.195589  0.163962  0.204328  0.183521  0.181856   \n",
       "TR-Turkish train       0.217998  0.174834  0.201870  0.189716  0.164862   \n",
       "           validation  0.228398  0.163083  0.202840  0.199594  0.167546   \n",
       "ZH-Chinese train       0.295387  0.275206  0.288063  0.040517  0.226664   \n",
       "           validation  0.299270  0.267640  0.310219  0.040146  0.210868   \n",
       "\n",
       "                            PER  \n",
       "lang       type                  \n",
       "BN-Bangla  train       0.170357  \n",
       "           validation  0.170157  \n",
       "DE-German  train       0.253292  \n",
       "           validation  0.272617  \n",
       "EN-English train       0.260132  \n",
       "           validation  0.250307  \n",
       "ES-Spanish train       0.240299  \n",
       "           validation  0.257502  \n",
       "FA-Farsi   train       0.221195  \n",
       "           validation  0.260601  \n",
       "HI-Hindi   train       0.155711  \n",
       "           validation  0.158579  \n",
       "KO-Korean  train       0.228061  \n",
       "           validation  0.250803  \n",
       "NL-Dutch   train       0.229381  \n",
       "           validation  0.232843  \n",
       "RU-Russian train       0.219974  \n",
       "           validation  0.209738  \n",
       "TR-Turkish train       0.233580  \n",
       "           validation  0.210142  \n",
       "ZH-Chinese train       0.115864  \n",
       "           validation  0.100973  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_counts['type'] = 'train'\n",
    "entity_counts.loc[val_indices, 'type'] = 'validation'\n",
    "\n",
    "entity_counts.groupby(['lang', 'type'])[entity_names].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-tactics",
   "metadata": {},
   "source": [
    "И так же, как и в EDA, посмотрим на разницу средних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forbidden-conditioning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOC     0.016478\n",
       "PROD    0.011751\n",
       "CW      0.028830\n",
       "GRP     0.021011\n",
       "CORP    0.022991\n",
       "PER     0.039406\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_langmeans = entity_counts.groupby(['lang', 'type'])[entity_names].mean().reset_index(level=1)\n",
    "val_langmeans_diffs = (val_langmeans.loc[val_langmeans['type'] == 'train', entity_names] - val_langmeans.loc[val_langmeans['type'] == 'validation', entity_names]).abs()\n",
    "val_langmeans_diffs.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-financing",
   "metadata": {},
   "source": [
    "В целом, разбиение получилось довольно близким, хотя местами есть довольно заметная разница"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "photographic-sigma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORP</th>\n",
       "      <th>CW</th>\n",
       "      <th>GRP</th>\n",
       "      <th>LOC</th>\n",
       "      <th>PER</th>\n",
       "      <th>PROD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BN-Bangla</th>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.026938</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.028916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE-German</th>\n",
       "      <td>-0.000963</td>\n",
       "      <td>-0.017403</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.023733</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.016956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN-English</th>\n",
       "      <td>0.010122</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.017992</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.007138</td>\n",
       "      <td>-0.006224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES-Spanish</th>\n",
       "      <td>-0.001432</td>\n",
       "      <td>-0.021851</td>\n",
       "      <td>-0.009069</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>-0.012881</td>\n",
       "      <td>-0.008367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FA-Farsi</th>\n",
       "      <td>-0.009287</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>-0.013155</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>-0.019455</td>\n",
       "      <td>-0.002389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HI-Hindi</th>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.006756</td>\n",
       "      <td>-0.002494</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.010155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KO-Korean</th>\n",
       "      <td>0.013035</td>\n",
       "      <td>-0.021874</td>\n",
       "      <td>-0.017212</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.012357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL-Dutch</th>\n",
       "      <td>0.005798</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>-0.007855</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.009797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RU-Russian</th>\n",
       "      <td>0.000245</td>\n",
       "      <td>-0.013162</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>-0.013774</td>\n",
       "      <td>-0.009370</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TR-Turkish</th>\n",
       "      <td>-0.000478</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>0.017678</td>\n",
       "      <td>0.009927</td>\n",
       "      <td>-0.023242</td>\n",
       "      <td>-0.010942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZH-Chinese</th>\n",
       "      <td>-0.007928</td>\n",
       "      <td>-0.012540</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>-0.013355</td>\n",
       "      <td>0.008446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CORP        CW       GRP       LOC       PER      PROD\n",
       "lang                                                                  \n",
       "BN-Bangla   0.010968  0.008954  0.009547  0.026938  0.009474  0.028916\n",
       "DE-German  -0.000963 -0.017403  0.006409  0.023733  0.004270  0.016956\n",
       "EN-English  0.010122 -0.004084 -0.017992  0.012030 -0.007138 -0.006224\n",
       "ES-Spanish -0.001432 -0.021851 -0.009069  0.011978 -0.012881 -0.008367\n",
       "FA-Farsi   -0.009287  0.005807 -0.013155  0.001977 -0.019455 -0.002389\n",
       "HI-Hindi    0.008152  0.006756 -0.002494  0.005789  0.005989  0.010155\n",
       "KO-Korean   0.013035 -0.021874 -0.017212  0.008581  0.001743  0.012357\n",
       "NL-Dutch    0.005798 -0.004354 -0.007855 -0.003275  0.008972  0.009797\n",
       "RU-Russian  0.000245 -0.013162  0.001360 -0.013774 -0.009370  0.002089\n",
       "TR-Turkish -0.000478 -0.000496  0.017678  0.009927 -0.023242 -0.010942\n",
       "ZH-Chinese -0.007928 -0.012540  0.008836  0.012130 -0.013355  0.008446"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langmeans_diffs.set_index('lang') - val_langmeans_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-reconstruction",
   "metadata": {},
   "source": [
    "В принципе, удалось разбить немного получше, чем в train/dev разбиении от оргов. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-lingerie",
   "metadata": {},
   "source": [
    "# Сохраняем разбиение\n",
    "\n",
    "Тут есть сложность, связанная с тем, что датасет в json может сгенерироваться немного по-разному. \n",
    "\n",
    "Самый верный способ: сохранить новое разбиение в том же CONLL, что и исходные данные. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b3b886e-9c10-40f7-bc3f-ad817ad84b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['27',\n",
       "  'декабря',\n",
       "  '2014',\n",
       "  'общественная',\n",
       "  'организация',\n",
       "  '«',\n",
       "  'закарпатська',\n",
       "  'волонтерська',\n",
       "  'сотня',\n",
       "  '»',\n",
       "  'передала',\n",
       "  'батальону',\n",
       "  'внедорожник',\n",
       "  'mitsubishi',\n",
       "  'l200',\n",
       "  '.'],\n",
       " 'token_labels': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-PROD',\n",
       "  'I-PROD',\n",
       "  'O'],\n",
       " 'lang': 'RU-Russian',\n",
       " 'id': '0e4785d0-9fea-4cea-9a95-354152b8e9e4',\n",
       " 'domain': 'train',\n",
       " 'type': 'train'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[125074]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8127e54d-561c-46e5-8390-d120c02ac530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1b49023e5245f2ac5d821c00f6aeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def sample_to_conll(sample):\n",
    "    lines = []\n",
    "    lines.append(f\"# id {sample['id']}\tdomain={sample['domain']}\")  # Решил поле \"domain\" пока не трогать\n",
    "    for token, token_label in zip(sample['tokens'], sample['token_labels']):\n",
    "        lines.append(f\"{token} _ _ {token_label}\")\n",
    "    return lines\n",
    "\n",
    "path_to_save_data = Path('../data/processed_data/')\n",
    "\n",
    "for i, sample in tqdm(enumerate(data), total=len(data)):\n",
    "    path_to_folder = path_to_save_data / sample['lang']\n",
    "    if not path_to_folder.exists():\n",
    "        os.mkdir(path_to_folder)\n",
    "    \n",
    "    sample_type = 'validation' if i in val_indices else 'train'\n",
    "    \n",
    "    with open(path_to_folder / f'{sample_type}.conll', 'a') as f:\n",
    "        lines = sample_to_conll(sample)\n",
    "        f.write('\\n'.join(lines))\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-analysis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [SRU]",
   "language": "python",
   "name": "sru_lm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
