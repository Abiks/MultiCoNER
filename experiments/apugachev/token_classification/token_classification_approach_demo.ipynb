{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc04eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import os, operator\n",
    "from progressbar import progressbar as pb\n",
    "from nltk import word_tokenize\n",
    "from typing import List, Tuple\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "import gdown #! pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02524a3b-5bd5-4c24-9a06-28ef64e55a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-9W24SpNbBEL9Z_tVfT52UJdi-tgxh21\n",
      "To: /Users/alex/Python/multiconer/my_experiments/models/token_classification/token_classification_sbert_large_nlu_ru.zip\n",
      "100%|██████████████████████████████████████| 1.58G/1.58G [02:23<00:00, 11.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "! gdown https://drive.google.com/uc?id=1-9W24SpNbBEL9Z_tVfT52UJdi-tgxh21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fe1d55b-4711-4136-9d96-365b1e3630bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  token_classification_sbert_large_nlu_ru.zip\n",
      "   creating: token_classification_sbert_large_nlu_ru/\n",
      "  inflating: token_classification_sbert_large_nlu_ru/config.json  \n",
      "  inflating: __MACOSX/token_classification_sbert_large_nlu_ru/._config.json  \n",
      "  inflating: token_classification_sbert_large_nlu_ru/pytorch_model.bin  \n",
      "  inflating: __MACOSX/token_classification_sbert_large_nlu_ru/._pytorch_model.bin  \n"
     ]
    }
   ],
   "source": [
    "! unzip token_classification_sbert_large_nlu_ru.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e697468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../../SemEval2022-Task11_Train-Dev/RU-Russian/\"\n",
    "pretrained = \"sberbank-ai/sbert_large_nlu_ru\"\n",
    "SAVE_PATH = \"token_classification_sbert_large_nlu_ru/\"\n",
    "device = 'cpu'\n",
    "\n",
    "max_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368eb2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, \"ru_dev.conll\")) as f:\n",
    "    dev_file = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d2cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conll(file) -> Tuple[List, List]:\n",
    "    texts, labels = [], []\n",
    "    \n",
    "    for row in file:\n",
    "        if row.startswith(\"#\"):\n",
    "            new_texts, new_labels = [], []\n",
    "            continue\n",
    "\n",
    "        if row == \"\":\n",
    "            texts.append(new_texts)\n",
    "            labels.append(new_labels)\n",
    "\n",
    "        else:\n",
    "            parts = row.split()\n",
    "            new_texts.append(parts[0])\n",
    "            new_labels.append(parts[-1])\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "dev_texts, dev_labels = parse_conll(dev_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97a58db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b058f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_LABEL2ID = {\n",
    "    'O': 0, 'B-CORP': 1, 'B-CW': 2,\n",
    "    'B-GRP': 3, 'B-LOC': 4, 'B-PER': 5,\n",
    "    'B-PROD': 6, 'I-CORP': 7, 'I-CW': 8,\n",
    "    'I-GRP': 9, 'I-LOC': 10, 'I-PER': 11,\n",
    "    'I-PROD': 12\n",
    "}\n",
    "\n",
    "GLOBAL_ID2LABEL = {idx: label for label, idx in GLOBAL_LABEL2ID.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8149ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained, local_files_only=True)\n",
    "\n",
    "O_TAG = 'O'\n",
    "B_TAG = 'B-'\n",
    "I_TAG = 'I-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5fcd514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_len, pad_token):\n",
    "    if len(seq) >= max_len:\n",
    "        seq = seq[:max_len]\n",
    "    else:\n",
    "        seq = seq + [pad_token] * (max_len - len(seq))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5192163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tokens(words, labels):\n",
    "    \n",
    "    bert_tokens, bio_labels = [tokenizer.cls_token], [O_TAG]\n",
    "    \n",
    "    for word, label in zip(words, labels):\n",
    "        tokens = tokenizer.tokenize(word)\n",
    "        bert_tokens.extend(tokens)\n",
    "        \n",
    "        new_labels = [label] * len(tokens)\n",
    "        bio_labels.extend(new_labels)\n",
    "        \n",
    "    bert_tokens.append(tokenizer.sep_token)\n",
    "    bio_labels.append(O_TAG)\n",
    "    \n",
    "    for i, (token, label) in enumerate(zip(bert_tokens, bio_labels)):\n",
    "        if token.startswith(\"##\") and label.startswith(B_TAG):\n",
    "            bio_labels[i] = I_TAG + label[2:]\n",
    "\n",
    "    encoded_tokens = tokenizer.encode(bert_tokens, add_special_tokens=False)\n",
    "    \n",
    "    if len(bio_labels) >= max_len:\n",
    "        bio_labels[max_len-1] = O_TAG\n",
    "    \n",
    "    bio_labels = pad_sequence(bio_labels, max_len, O_TAG)\n",
    "    encoded_tokens = pad_sequence(encoded_tokens, max_len, tokenizer.pad_token_id)\n",
    "\n",
    "    return encoded_tokens, bio_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47834af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_ner(texts, labels):\n",
    "    result = np.zeros((len(texts), max_len), dtype=np.int32)\n",
    "    fin_labels, fin_labels_encoded = [], []\n",
    "\n",
    "    for i, (text, label) in pb(enumerate(zip(texts, labels))):\n",
    "        \n",
    "        c_words, c_labels = process_tokens(text, label) \n",
    "        assert len(c_words) == len(c_labels)\n",
    "        \n",
    "        result[i] = c_words\n",
    "        fin_labels.append(c_labels)\n",
    "    \n",
    "    words_ids, labels_ids = [], []\n",
    "    \n",
    "    for sentence in fin_labels:\n",
    "        new_labels = []\n",
    "        for label in sentence:\n",
    "            new_labels.append(GLOBAL_LABEL2ID[label])\n",
    "        fin_labels_encoded.append(new_labels)\n",
    "    \n",
    "    return result, fin_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d8739c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |           #                                     | 799 Elapsed Time: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "dev_words_enc, dev_labels_enc = prepare_data_for_ner(dev_texts, dev_labels)\n",
    "dev_data = np.stack((dev_words_enc, dev_labels_enc), axis=1)\n",
    "dev_batches = DataLoader(dev_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f503261",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bfac87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(SAVE_PATH, local_files_only=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f71d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(c_model, batches):\n",
    "    pred_labels = []\n",
    "\n",
    "    for item in pb(batches):\n",
    "        item = item[:, 0, :]\n",
    "        out = c_model(item.to(device))\n",
    "        logits = out.logits\n",
    "        logits = logits.argmax(axis=-1).tolist()\n",
    "        pred_labels.extend(logits)\n",
    "        \n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04694e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_preds_for_calc_metrics(pred_encoded, test_encoded, test_words):\n",
    "    pred_extended, test_extended, pred_decoded = [], [], []\n",
    "\n",
    "    for pred, test, words in zip(pred_encoded, test_encoded, test_words):\n",
    "        words = words.tolist()\n",
    "        \n",
    "        words_encoded = tokenizer.convert_ids_to_tokens(words)\n",
    "\n",
    "        if 0 in words:\n",
    "            cut_ind = words.index(0)\n",
    "        else:\n",
    "            cut_ind = max_len\n",
    "\n",
    "        pred, test = pred[:cut_ind], test[:cut_ind]\n",
    "        pred, test = pred[1:-1], test[1:-1]\n",
    "        \n",
    "        pred = [GLOBAL_ID2LABEL[num] for i, num in enumerate(pred) \n",
    "            if not words_encoded[i].startswith('##')]\n",
    "        test = [GLOBAL_ID2LABEL[num] for i, num in enumerate(test) \n",
    "            if not words_encoded[i].startswith('##')]\n",
    "\n",
    "        pred_extended.extend(pred)\n",
    "        pred_decoded.append(pred)\n",
    "        test_extended.extend(test)\n",
    "        assert len(pred) == len(test)\n",
    "    \n",
    "    return pred_extended, test_extended, pred_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dfb1832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (200 of 200) |######################| Elapsed Time: 0:06:59 Time:  0:06:59\n"
     ]
    }
   ],
   "source": [
    "pred_labels_enc = get_predictions(model, dev_batches)\n",
    "pred_extended, true_extended, pred_labels_decoded = prepare_preds_for_calc_metrics(\n",
    "    pred_labels_enc, dev_labels_enc, dev_words_enc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f43f4",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c583893",
   "metadata": {},
   "source": [
    "### Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75ae2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idx = [223, 0, 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75339322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['сан', 'педро', 'де', 'атакама', '(', ')', '—', 'посёлок', 'в', 'чили', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "\n",
      "Text: ['важным', 'традиционным', 'промыслом', 'является', 'производство', 'пальмового', 'масла', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'B-PROD', 'I-PROD', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'B-PROD', 'I-PROD', 'O']\n",
      "\n",
      "Text: ['в', '1862', 'году', 'стал', 'членом', 'правления', 'русского', 'общества', 'пароходства', 'и', 'торговли', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'O', 'B-CORP', 'I-CORP', 'I-CORP', 'I-CORP', 'I-CORP', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'B-CORP', 'I-CORP', 'I-CORP', 'I-CORP', 'I-CORP', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in good_idx:\n",
    "    print(f\"Text: {dev_texts[idx]}\")\n",
    "    print(f\"True: {dev_labels[idx]}\")\n",
    "    print(f\"Pred: {pred_labels_decoded[idx]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb243530",
   "metadata": {},
   "source": [
    "### Bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74d17652",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx = [9, 673, 722]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "674e0853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['по', 'состоянию', 'на', '1', 'января', '2014', 'года', 'в', 'минской', 'подземке', 'установлено', '996', 'видеокамер', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PROD', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Text: ['собор', 'святого', 'иоанна', '—', 'протестантская', 'христианская', 'церковь', ',', 'расположена', 'в', 'шанхае', ',', 'китай', ',', 'в', 'районе', 'чаннин', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "Pred: ['B-LOC', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'I-LOC']\n",
      "\n",
      "Text: ['после', 'распада', 'ссср', 'начались', 'массовые', 'отмены', 'пригородных', 'поездов', 'по', 'всей', 'донецкой', 'железной', 'дороге', '.']\n",
      "True: ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CORP', 'I-CORP', 'I-CORP', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PROD', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in bad_idx:\n",
    "    print(f\"Text: {dev_texts[idx]}\")\n",
    "    print(f\"True: {dev_labels[idx]}\")\n",
    "    print(f\"Pred: {pred_labels_decoded[idx]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd6070a",
   "metadata": {},
   "source": [
    "# Calc Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be08ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_true = [item.replace(\"I-\", \"\").replace(\"B-\", \"\") for item in true_extended]\n",
    "flat_pred = [item.replace(\"I-\", \"\").replace(\"B-\", \"\") for item in pred_extended]\n",
    "assert len(flat_true) == len(flat_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349ffbe",
   "metadata": {},
   "source": [
    "### Micro Avg. on all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "709b566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "avg = \"micro\"\n",
    "\n",
    "result[\"ALL\"] = {\n",
    "    \"precision\": precision_score(flat_true, flat_pred, average=avg),\n",
    "    \"recall\": recall_score(flat_true, flat_pred, average=avg),\n",
    "    \"f1\": f1_score(flat_true, flat_pred, average=avg)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744d313",
   "metadata": {},
   "source": [
    "### By class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e048574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [\"O\", 'CORP', 'CW', 'GRP', 'LOC', 'PER', 'PROD']:\n",
    "    precision = precision_score(flat_true, flat_pred, labels=[label], average=avg)\n",
    "    recall = recall_score(flat_true, flat_pred, labels=[label], average=avg)\n",
    "    f1 = f1_score(flat_true, flat_pred, labels=[label], average=avg)\n",
    "    \n",
    "    result[label] = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d17a9a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL</th>\n",
       "      <th>O</th>\n",
       "      <th>CORP</th>\n",
       "      <th>CW</th>\n",
       "      <th>GRP</th>\n",
       "      <th>LOC</th>\n",
       "      <th>PER</th>\n",
       "      <th>PROD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.923568</td>\n",
       "      <td>0.954357</td>\n",
       "      <td>0.837143</td>\n",
       "      <td>0.789082</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.827640</td>\n",
       "      <td>0.693215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.923568</td>\n",
       "      <td>0.966294</td>\n",
       "      <td>0.736181</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>0.719424</td>\n",
       "      <td>0.751579</td>\n",
       "      <td>0.828927</td>\n",
       "      <td>0.804795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.923568</td>\n",
       "      <td>0.960288</td>\n",
       "      <td>0.783422</td>\n",
       "      <td>0.733564</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.769397</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.744849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ALL         O      CORP        CW       GRP       LOC  \\\n",
       "precision  0.923568  0.954357  0.837143  0.789082  0.813008  0.788079   \n",
       "recall     0.923568  0.966294  0.736181  0.685345  0.719424  0.751579   \n",
       "f1         0.923568  0.960288  0.783422  0.733564  0.763359  0.769397   \n",
       "\n",
       "                PER      PROD  \n",
       "precision  0.827640  0.693215  \n",
       "recall     0.828927  0.804795  \n",
       "f1         0.828283  0.744849  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78292072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
