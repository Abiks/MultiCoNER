{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "129109db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import os, operator\n",
    "from progressbar import progressbar as pb\n",
    "from nltk import word_tokenize\n",
    "from typing import List, Tuple\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3992cb64",
   "metadata": {},
   "source": [
    "# Read data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ca5f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../SemEval2022-Task11_Train-Dev/RU-Russian/\"\n",
    "pretrained_path = \"../../pretrained/sbert_large_nlu_ru/\"\n",
    "SAVE_PATH = \"models/token_classification/sbert_large_nlu_ru/\"\n",
    "device = 'cuda'\n",
    "\n",
    "max_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "739572f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, \"ru_train.conll\")) as f:\n",
    "    train_file = f.read().splitlines()\n",
    "    \n",
    "with open(os.path.join(data_path, \"ru_dev.conll\")) as f:\n",
    "    dev_file = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06d217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conll(file) -> Tuple[List, List]:\n",
    "    texts, labels = [], []\n",
    "    \n",
    "    for row in file:\n",
    "        if row.startswith(\"#\"):\n",
    "            new_texts, new_labels = [], []\n",
    "            continue\n",
    "\n",
    "        if row == \"\":\n",
    "            texts.append(new_texts)\n",
    "            labels.append(new_labels)\n",
    "\n",
    "        else:\n",
    "            parts = row.split()\n",
    "            new_texts.append(parts[0])\n",
    "            new_labels.append(parts[-1])\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = parse_conll(train_file)\n",
    "dev_texts, dev_labels = parse_conll(dev_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461ca24",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9861de3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-CORP': 1,\n",
       " 'B-CW': 2,\n",
       " 'B-GRP': 3,\n",
       " 'B-LOC': 4,\n",
       " 'B-PER': 5,\n",
       " 'B-PROD': 6,\n",
       " 'I-CORP': 7,\n",
       " 'I-CW': 8,\n",
       " 'I-GRP': 9,\n",
       " 'I-LOC': 10,\n",
       " 'I-PER': 11,\n",
       " 'I-PROD': 12}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_labels = set()\n",
    "for item in train_labels:\n",
    "    uniq_labels.update(item)\n",
    "    \n",
    "uniq_labels = sorted(list(uniq_labels))\n",
    "uniq_labels.remove(O_TAG)\n",
    "uniq_labels.insert(0, O_TAG)\n",
    "    \n",
    "GLOBAL_LABEL2ID = {label: idx for idx, label in enumerate(uniq_labels)}\n",
    "GLOBAL_ID2LABEL = {idx: label for label, idx in GLOBAL_LABEL2ID.items()}\n",
    "GLOBAL_LABEL2ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3fadba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "O_TAG = 'O'\n",
    "B_TAG = 'B-'\n",
    "I_TAG = 'I-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45ec692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_len, pad_token):\n",
    "    if len(seq) >= max_len:\n",
    "        seq = seq[:max_len]\n",
    "    else:\n",
    "        seq = seq + [pad_token] * (max_len - len(seq))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb7c94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tokens(words, labels):\n",
    "    \n",
    "    bert_tokens, bio_labels = [tokenizer.cls_token], [O_TAG]\n",
    "    \n",
    "    for word, label in zip(words, labels):\n",
    "        tokens = tokenizer.tokenize(word)\n",
    "        bert_tokens.extend(tokens)\n",
    "        \n",
    "        new_labels = [label] * len(tokens)\n",
    "        bio_labels.extend(new_labels)\n",
    "        \n",
    "    bert_tokens.append(tokenizer.sep_token)\n",
    "    bio_labels.append(O_TAG)\n",
    "    \n",
    "    for i, (token, label) in enumerate(zip(bert_tokens, bio_labels)):\n",
    "        if token.startswith(\"##\") and label.startswith(B_TAG):\n",
    "            bio_labels[i] = I_TAG + label[2:]\n",
    "\n",
    "    encoded_tokens = tokenizer.encode(bert_tokens, add_special_tokens=False)\n",
    "    \n",
    "    if len(bio_labels) >= max_len:\n",
    "        bio_labels[max_len-1] = O_TAG\n",
    "    \n",
    "    bio_labels = pad_sequence(bio_labels, max_len, O_TAG)\n",
    "    encoded_tokens = pad_sequence(encoded_tokens, max_len, tokenizer.pad_token_id)\n",
    "\n",
    "    return encoded_tokens, bio_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b74fdb5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_data_for_ner(texts, labels):\n",
    "    result = np.zeros((len(texts), max_len), dtype=np.int32)\n",
    "    fin_labels, fin_labels_encoded = [], []\n",
    "\n",
    "    for i, (text, label) in pb(enumerate(zip(texts, labels))):\n",
    "        \n",
    "        c_words, c_labels = process_tokens(text, label) \n",
    "        assert len(c_words) == len(c_labels)\n",
    "        \n",
    "        result[i] = c_words\n",
    "        fin_labels.append(c_labels)\n",
    "    \n",
    "    words_ids, labels_ids = [], []\n",
    "    \n",
    "    for sentence in fin_labels:\n",
    "        new_labels = []\n",
    "        for label in sentence:\n",
    "            new_labels.append(GLOBAL_LABEL2ID[label])\n",
    "        fin_labels_encoded.append(new_labels)\n",
    "    \n",
    "    return result, fin_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ac51e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                                 #             | 15299 Elapsed Time: 0:00:15\n",
      "| |        #                                        | 799 Elapsed Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "train_words_enc, train_labels_enc = prepare_data_for_ner(train_texts, train_labels)\n",
    "dev_words_enc, dev_labels_enc = prepare_data_for_ner(dev_texts, dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc43eab",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c82c6e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ../../pretrained/sbert_large_nlu_ru/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(pretrained_path, num_labels=len(GLOBAL_ID2LABEL))\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b22f7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "batch_size = 32\n",
    "patience = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "227be8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.stack((train_words_enc, train_labels_enc), axis=1)\n",
    "dev_data = np.stack((dev_words_enc, dev_labels_enc), axis=1)\n",
    "\n",
    "train_batches = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "dev_batches = DataLoader(dev_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d23b23",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21f3e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "154bb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train(model, train_loader, optimizer, epoch_num):\n",
    "    train_loss, train_acc, train_f1 = [], [], []\n",
    "    model.train()\n",
    "\n",
    "    for batch_num, batch in enumerate(train_loader):\n",
    "        X_batch, y_batch = batch[:, 0, :], batch[:, 1, :]\n",
    "        X_batch = X_batch.type(torch.LongTensor).to(device)\n",
    "        y_batch = y_batch.type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(input_ids=X_batch, labels=y_batch.contiguous(), return_dict=True)\n",
    "        loss = out.loss\n",
    "        y_pred = out.logits\n",
    "        y_pred = torch.argmax(y_pred, dim=2)\n",
    "\n",
    "        y_pred_flatten = torch.flatten(y_pred).cpu().numpy()\n",
    "        y_batch_flatten = torch.flatten(y_batch).cpu().numpy()\n",
    "        f1 = f1_score(y_batch_flatten, y_pred_flatten, average=\"micro\")\n",
    "        accuracy = accuracy_score(y_batch_flatten, y_pred_flatten)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(accuracy)\n",
    "        train_f1.append(f1)\n",
    "        \n",
    "        if batch_num % 50 == 0:\n",
    "            print(f\"TRAIN: Epoch: {epoch_num}, Batch: {batch_num + 1} / {len(train_loader)}, \"\n",
    "                          f\"Loss: {loss.item():.3f}, Accuracy: {accuracy:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return np.mean(train_loss), np.mean(train_acc), np.mean(train_f1)\n",
    "\n",
    "def _val(model, val_loader, epoch_num):\n",
    "    val_loss, val_acc, val_f1 = [], [], []\n",
    "    model.eval()\n",
    "\n",
    "    for batch_num, batch in enumerate(val_loader):\n",
    "        X_batch, y_batch = batch[:, 0, :], batch[:, 1, :]\n",
    "        X_batch = X_batch.type(torch.LongTensor).to(device)\n",
    "        y_batch = y_batch.type(torch.LongTensor).to(device)\n",
    "\n",
    "        out = model(input_ids=X_batch, labels=y_batch.contiguous())\n",
    "        loss = out.loss\n",
    "        y_pred = out.logits\n",
    "        y_pred = torch.argmax(y_pred, dim=2)\n",
    "\n",
    "        y_pred_flatten = torch.flatten(y_pred).cpu().numpy()\n",
    "        y_batch_flatten = torch.flatten(y_batch).cpu().numpy()\n",
    "        f1 = f1_score(y_batch_flatten, y_pred_flatten, average=\"micro\")\n",
    "        accuracy = accuracy_score(y_batch_flatten, y_pred_flatten)\n",
    "\n",
    "        val_loss.append(loss.item())\n",
    "        val_acc.append(accuracy)\n",
    "        val_f1.append(f1)\n",
    "        \n",
    "        if batch_num % 50 == 0:\n",
    "            print(f\"VAL: Epoch: {epoch_num}, Batch: {batch_num + 1} / {len(val_loader)}, \"\n",
    "                          f\"Loss: {loss.item():.3f}, Accuracy: {accuracy:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "    return np.mean(val_loss), np.mean(val_acc), np.mean(val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "baa7c5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Epoch: 1, Batch: 1 / 479, Loss: 2.521, Accuracy: 0.062, F1: 0.062\n",
      "TRAIN: Epoch: 1, Batch: 51 / 479, Loss: 0.193, Accuracy: 0.939, F1: 0.939\n",
      "TRAIN: Epoch: 1, Batch: 101 / 479, Loss: 0.154, Accuracy: 0.946, F1: 0.946\n",
      "TRAIN: Epoch: 1, Batch: 151 / 479, Loss: 0.111, Accuracy: 0.958, F1: 0.958\n",
      "TRAIN: Epoch: 1, Batch: 201 / 479, Loss: 0.126, Accuracy: 0.954, F1: 0.954\n",
      "TRAIN: Epoch: 1, Batch: 251 / 479, Loss: 0.125, Accuracy: 0.964, F1: 0.964\n",
      "TRAIN: Epoch: 1, Batch: 301 / 479, Loss: 0.107, Accuracy: 0.960, F1: 0.960\n",
      "TRAIN: Epoch: 1, Batch: 351 / 479, Loss: 0.131, Accuracy: 0.947, F1: 0.947\n",
      "TRAIN: Epoch: 1, Batch: 401 / 479, Loss: 0.063, Accuracy: 0.979, F1: 0.979\n",
      "TRAIN: Epoch: 1, Batch: 451 / 479, Loss: 0.063, Accuracy: 0.979, F1: 0.979\n",
      "VAL: Epoch: 1, Batch: 1 / 25, Loss: 0.101, Accuracy: 0.954, F1: 0.954\n",
      "After epoch #1:\n",
      "Train loss: 0.133, Train Accuracy: 0.957, Train F1: 0.957\n",
      "Dev loss: 0.091, Dev Accuracy: 0.969, Dev F1: 0.969\n",
      "\n",
      "TRAIN: Epoch: 2, Batch: 1 / 479, Loss: 0.056, Accuracy: 0.981, F1: 0.981\n",
      "TRAIN: Epoch: 2, Batch: 51 / 479, Loss: 0.054, Accuracy: 0.977, F1: 0.977\n",
      "TRAIN: Epoch: 2, Batch: 101 / 479, Loss: 0.053, Accuracy: 0.982, F1: 0.982\n",
      "TRAIN: Epoch: 2, Batch: 151 / 479, Loss: 0.066, Accuracy: 0.981, F1: 0.981\n",
      "TRAIN: Epoch: 2, Batch: 201 / 479, Loss: 0.070, Accuracy: 0.972, F1: 0.972\n",
      "TRAIN: Epoch: 2, Batch: 251 / 479, Loss: 0.046, Accuracy: 0.983, F1: 0.983\n",
      "TRAIN: Epoch: 2, Batch: 301 / 479, Loss: 0.049, Accuracy: 0.982, F1: 0.982\n",
      "TRAIN: Epoch: 2, Batch: 351 / 479, Loss: 0.071, Accuracy: 0.979, F1: 0.979\n",
      "TRAIN: Epoch: 2, Batch: 401 / 479, Loss: 0.089, Accuracy: 0.969, F1: 0.969\n",
      "TRAIN: Epoch: 2, Batch: 451 / 479, Loss: 0.052, Accuracy: 0.981, F1: 0.981\n",
      "VAL: Epoch: 2, Batch: 1 / 25, Loss: 0.071, Accuracy: 0.969, F1: 0.969\n",
      "After epoch #2:\n",
      "Train loss: 0.068, Train Accuracy: 0.977, Train F1: 0.977\n",
      "Dev loss: 0.086, Dev Accuracy: 0.971, Dev F1: 0.971\n",
      "\n",
      "TRAIN: Epoch: 3, Batch: 1 / 479, Loss: 0.056, Accuracy: 0.980, F1: 0.980\n",
      "TRAIN: Epoch: 3, Batch: 51 / 479, Loss: 0.042, Accuracy: 0.990, F1: 0.990\n",
      "TRAIN: Epoch: 3, Batch: 101 / 479, Loss: 0.027, Accuracy: 0.991, F1: 0.991\n",
      "TRAIN: Epoch: 3, Batch: 151 / 479, Loss: 0.045, Accuracy: 0.982, F1: 0.982\n",
      "TRAIN: Epoch: 3, Batch: 201 / 479, Loss: 0.076, Accuracy: 0.975, F1: 0.975\n",
      "TRAIN: Epoch: 3, Batch: 251 / 479, Loss: 0.068, Accuracy: 0.976, F1: 0.976\n",
      "TRAIN: Epoch: 3, Batch: 301 / 479, Loss: 0.022, Accuracy: 0.994, F1: 0.994\n",
      "TRAIN: Epoch: 3, Batch: 351 / 479, Loss: 0.040, Accuracy: 0.985, F1: 0.985\n",
      "TRAIN: Epoch: 3, Batch: 401 / 479, Loss: 0.050, Accuracy: 0.983, F1: 0.983\n",
      "TRAIN: Epoch: 3, Batch: 451 / 479, Loss: 0.044, Accuracy: 0.981, F1: 0.981\n",
      "VAL: Epoch: 3, Batch: 1 / 25, Loss: 0.070, Accuracy: 0.979, F1: 0.979\n",
      "After epoch #3:\n",
      "Train loss: 0.046, Train Accuracy: 0.985, Train F1: 0.985\n",
      "Dev loss: 0.090, Dev Accuracy: 0.973, Dev F1: 0.973\n",
      "\n",
      "TRAIN: Epoch: 4, Batch: 1 / 479, Loss: 0.025, Accuracy: 0.994, F1: 0.994\n",
      "TRAIN: Epoch: 4, Batch: 51 / 479, Loss: 0.026, Accuracy: 0.991, F1: 0.991\n",
      "TRAIN: Epoch: 4, Batch: 101 / 479, Loss: 0.063, Accuracy: 0.979, F1: 0.979\n",
      "TRAIN: Epoch: 4, Batch: 151 / 479, Loss: 0.019, Accuracy: 0.995, F1: 0.995\n",
      "TRAIN: Epoch: 4, Batch: 201 / 479, Loss: 0.120, Accuracy: 0.962, F1: 0.962\n",
      "TRAIN: Epoch: 4, Batch: 251 / 479, Loss: 0.045, Accuracy: 0.984, F1: 0.984\n",
      "TRAIN: Epoch: 4, Batch: 301 / 479, Loss: 0.033, Accuracy: 0.990, F1: 0.990\n",
      "TRAIN: Epoch: 4, Batch: 351 / 479, Loss: 0.027, Accuracy: 0.992, F1: 0.992\n",
      "TRAIN: Epoch: 4, Batch: 401 / 479, Loss: 0.049, Accuracy: 0.984, F1: 0.984\n",
      "TRAIN: Epoch: 4, Batch: 451 / 479, Loss: 0.032, Accuracy: 0.986, F1: 0.986\n",
      "VAL: Epoch: 4, Batch: 1 / 25, Loss: 0.107, Accuracy: 0.969, F1: 0.969\n",
      "After epoch #4:\n",
      "Train loss: 0.043, Train Accuracy: 0.987, Train F1: 0.987\n",
      "Dev loss: 0.103, Dev Accuracy: 0.972, Dev F1: 0.972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_epoch = 0\n",
    "dev_losses = []\n",
    "patience = 1\n",
    "\n",
    "for epoch in range(1, 25 + 1):\n",
    "    train_loss, train_acc, train_f1 = _train(model, train_batches, optimizer, epoch)\n",
    "    dev_loss, dev_acc, dev_f1 = _val(model, dev_batches, epoch)\n",
    "\n",
    "    if len(dev_losses) == 0 or dev_loss < dev_losses[-1]:\n",
    "        model.save_pretrained(SAVE_PATH)\n",
    "\n",
    "    elif last_epoch == 0:\n",
    "        last_epoch = epoch + patience\n",
    "\n",
    "    print(f\"After epoch #{epoch}:\")\n",
    "    print(f\"Train loss: {train_loss:.3f}, Train Accuracy: {train_acc:.3f}, Train F1: {train_f1:.3f}\")\n",
    "    print(f\"Dev loss: {dev_loss:.3f}, Dev Accuracy: {dev_acc:.3f}, Dev F1: {dev_f1:.3f}\\n\")\n",
    "\n",
    "    dev_losses.append(dev_loss)\n",
    "    if epoch == last_epoch:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d03f57b",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b91f80c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(SAVE_PATH, local_files_only=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35793204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(c_model, batches):\n",
    "    pred_labels = []\n",
    "\n",
    "    for item in pb(batches):\n",
    "        item = item[:, 0, :]\n",
    "        out = c_model(item.to(device))\n",
    "        logits = out.logits\n",
    "        logits = logits.argmax(axis=-1).tolist()\n",
    "        pred_labels.extend(logits)\n",
    "        \n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97ad1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_preds_for_calc_metrics(pred_encoded, test_encoded, test_words):\n",
    "    pred_extended, test_extended, pred_decoded = [], [], []\n",
    "\n",
    "    for pred, test, words in zip(pred_encoded, test_encoded, test_words):\n",
    "        words = words.tolist()\n",
    "        \n",
    "        words_encoded = tokenizer.convert_ids_to_tokens(words)\n",
    "\n",
    "        if 0 in words:\n",
    "            cut_ind = words.index(0)\n",
    "        else:\n",
    "            cut_ind = max_len\n",
    "\n",
    "        pred, test = pred[:cut_ind], test[:cut_ind]\n",
    "        pred, test = pred[1:-1], test[1:-1]\n",
    "        \n",
    "        pred = [GLOBAL_ID2LABEL[num] for i, num in enumerate(pred) \n",
    "            if not words_encoded[i].startswith('##')]\n",
    "        test = [GLOBAL_ID2LABEL[num] for i, num in enumerate(test) \n",
    "            if not words_encoded[i].startswith('##')]\n",
    "\n",
    "        pred_extended.extend(pred)\n",
    "        pred_decoded.append(pred)\n",
    "        test_extended.extend(test)\n",
    "        assert len(pred) == len(test)\n",
    "    \n",
    "    return pred_extended, test_extended, pred_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "049c126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (25 of 25) |########################| Elapsed Time: 0:00:02 Time:  0:00:02\n"
     ]
    }
   ],
   "source": [
    "pred_labels_enc = get_predictions(model, dev_batches)\n",
    "pred_extended, true_extended, pred_labels_decoded = prepare_preds_for_calc_metrics(\n",
    "    pred_labels_enc, dev_labels_enc, dev_words_enc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c4293",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e8cb3",
   "metadata": {},
   "source": [
    "### Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1fcced3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idx = [223, 0, 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "018f13e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['сан', 'педро', 'де', 'атакама', '(', ')', '—', 'посёлок', 'в', 'чили', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "\n",
      "Text: ['важным', 'традиционным', 'промыслом', 'является', 'производство', 'пальмового', 'масла', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'B-PROD', 'I-PROD', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'B-PROD', 'I-PROD', 'O']\n",
      "\n",
      "Text: ['в', '1862', 'году', 'стал', 'членом', 'правления', 'русского', 'общества', 'пароходства', 'и', 'торговли', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'O', 'B-CORP', 'I-CORP', 'I-CORP', 'I-CORP', 'I-CORP', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'B-CORP', 'I-CORP', 'I-CORP', 'I-CORP', 'I-CORP', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in good_idx:\n",
    "    print(f\"Text: {dev_texts[idx]}\")\n",
    "    print(f\"True: {dev_labels[idx]}\")\n",
    "    print(f\"Pred: {pred_labels_decoded[idx]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b968613e",
   "metadata": {},
   "source": [
    "### Bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "630a06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx = [9, 673, 722]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8247844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['по', 'состоянию', 'на', '1', 'января', '2014', 'года', 'в', 'минской', 'подземке', 'установлено', '996', 'видеокамер', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PROD', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Text: ['собор', 'святого', 'иоанна', '—', 'протестантская', 'христианская', 'церковь', ',', 'расположена', 'в', 'шанхае', ',', 'китай', ',', 'в', 'районе', 'чаннин', '.']\n",
      "True: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "Pred: ['B-LOC', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'I-LOC']\n",
      "\n",
      "Text: ['после', 'распада', 'ссср', 'начались', 'массовые', 'отмены', 'пригородных', 'поездов', 'по', 'всей', 'донецкой', 'железной', 'дороге', '.']\n",
      "True: ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CORP', 'I-CORP', 'I-CORP', 'O']\n",
      "Pred: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PROD', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in bad_idx:\n",
    "    print(f\"Text: {dev_texts[idx]}\")\n",
    "    print(f\"True: {dev_labels[idx]}\")\n",
    "    print(f\"Pred: {pred_labels_decoded[idx]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8abb473",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "621b0823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flat_true = [item.replace(\"I-\", \"\").replace(\"B-\", \"\") for item in true_extended]\n",
    "flat_pred = [item.replace(\"I-\", \"\").replace(\"B-\", \"\") for item in pred_extended]\n",
    "assert len(flat_true) == len(flat_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eda02b",
   "metadata": {},
   "source": [
    "### Micro Avg. on all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f524e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "avg = \"micro\"\n",
    "\n",
    "result[\"ALL\"] = {\n",
    "    \"precision\": precision_score(flat_true, flat_pred, average=avg),\n",
    "    \"recall\": recall_score(flat_true, flat_pred, average=avg),\n",
    "    \"f1\": f1_score(flat_true, flat_pred, average=avg)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d10ee5",
   "metadata": {},
   "source": [
    "### By class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "461ce75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [\"O\", 'CORP', 'CW', 'GRP', 'LOC', 'PER', 'PROD']:\n",
    "    precision = precision_score(flat_true, flat_pred, labels=[label], average=avg)\n",
    "    recall = recall_score(flat_true, flat_pred, labels=[label], average=avg)\n",
    "    f1 = f1_score(flat_true, flat_pred, labels=[label], average=avg)\n",
    "    \n",
    "    result[label] = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1d0a8abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALL</th>\n",
       "      <th>O</th>\n",
       "      <th>CORP</th>\n",
       "      <th>CW</th>\n",
       "      <th>GRP</th>\n",
       "      <th>LOC</th>\n",
       "      <th>PER</th>\n",
       "      <th>PROD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.923568</td>\n",
       "      <td>0.954357</td>\n",
       "      <td>0.837143</td>\n",
       "      <td>0.789082</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.827640</td>\n",
       "      <td>0.693215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.923568</td>\n",
       "      <td>0.966294</td>\n",
       "      <td>0.736181</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>0.719424</td>\n",
       "      <td>0.751579</td>\n",
       "      <td>0.828927</td>\n",
       "      <td>0.804795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.923568</td>\n",
       "      <td>0.960288</td>\n",
       "      <td>0.783422</td>\n",
       "      <td>0.733564</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.769397</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.744849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ALL         O      CORP        CW       GRP       LOC  \\\n",
       "precision  0.923568  0.954357  0.837143  0.789082  0.813008  0.788079   \n",
       "recall     0.923568  0.966294  0.736181  0.685345  0.719424  0.751579   \n",
       "f1         0.923568  0.960288  0.783422  0.733564  0.763359  0.769397   \n",
       "\n",
       "                PER      PROD  \n",
       "precision  0.827640  0.693215  \n",
       "recall     0.828927  0.804795  \n",
       "f1         0.828283  0.744849  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b17152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
