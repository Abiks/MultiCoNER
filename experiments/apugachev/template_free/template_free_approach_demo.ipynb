{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "69128be7-936b-444e-9e37-0857bcd3549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "23830fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import os, operator\n",
    "from progressbar import progressbar as pb\n",
    "from nltk import word_tokenize\n",
    "from typing import List, Tuple\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "import gdown #! pip install gdown\n",
    "from span_metric import SpanF1\n",
    "\n",
    "span_f1 = SpanF1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9611a294-364c-40b3-ba84-b534421edca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-4fS0lwbS1fZcGmlOn2ro81X68zkQ8ZX\n",
      "To: /Users/alex/Python/multiconer/my_experiments/models/template_free/template_free_sbert_large_nlu_ru.zip\n",
      "100%|██████████████████████████████████████| 1.59G/1.59G [07:09<00:00, 3.69MB/s]\n"
     ]
    }
   ],
   "source": [
    "! gdown https://drive.google.com/uc?id=1-4fS0lwbS1fZcGmlOn2ro81X68zkQ8ZX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b66cf92-06fa-47ad-8c8c-e8b14a08b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  template_free_sbert_large_nlu_ru.zip\n",
      "   creating: sbert_large_nlu_ru/\n",
      "  inflating: sbert_large_nlu_ru/.DS_Store  \n",
      "  inflating: __MACOSX/sbert_large_nlu_ru/._.DS_Store  \n",
      "  inflating: sbert_large_nlu_ru/config.json  \n",
      "  inflating: __MACOSX/sbert_large_nlu_ru/._config.json  \n",
      "  inflating: sbert_large_nlu_ru/pytorch_model.bin  \n",
      "  inflating: __MACOSX/sbert_large_nlu_ru/._pytorch_model.bin  \n"
     ]
    }
   ],
   "source": [
    "! unzip template_free_sbert_large_nlu_ru.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c687efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../../SemEval2022-Task11_Train-Dev/RU-Russian/\"\n",
    "pretrained = \"sberbank-ai/sbert_large_nlu_ru\"\n",
    "SAVE_PATH = \"sbert_large_nlu_ru/\"\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69694c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, \"ru_dev.conll\")) as f:\n",
    "    dev_file = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ade3c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conll(file) -> Tuple[List, List]:\n",
    "    texts, labels = [], []\n",
    "    \n",
    "    for row in file:\n",
    "        if row.startswith(\"#\"):\n",
    "            new_texts, new_labels = [], []\n",
    "            continue\n",
    "\n",
    "        if row == \"\":\n",
    "            texts.append(new_texts)\n",
    "            labels.append(new_labels)\n",
    "\n",
    "        else:\n",
    "            parts = row.split()\n",
    "            new_texts.append(parts[0])\n",
    "            new_labels.append(parts[-1])\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "dev_texts, dev_labels = parse_conll(dev_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d403a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10fd734b-7c04-427b-bd27-04442bbc63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2word_label = { # label words dict\n",
    "    \"GRP\": \"колхоз\",\n",
    "    \"PER\": \"человек\",\n",
    "    \"CW\": \"сингл\",\n",
    "    \"PROD\": \"dvd\",\n",
    "    \"CORP\": \"mtv\",\n",
    "    \"LOC\": \"париж\"\n",
    "}\n",
    "\n",
    "word_label2label = {v:k for k, v in label2word_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a904465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_target(tokens, labels, label2word_label=label2word_label):\n",
    "    \"\"\"\n",
    "        Replace entities with label words\n",
    "    \"\"\"\n",
    "    new_tokens = []\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if label.startswith(\"B-\"):\n",
    "            prefix, tag = label.split(\"-\")\n",
    "            new_token = label2word_label[tag]\n",
    "            new_tokens.append(new_token)\n",
    "        elif label.startswith(\"I-\"):\n",
    "            continue\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "    \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b9a804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = []\n",
    "    \n",
    "for tokens, label_list in zip(dev_texts, dev_labels):\n",
    "    target = prepare_target(tokens, label_list)\n",
    "    x = \" \".join(tokens)\n",
    "    y = \" \".join(target)\n",
    "    dev_data.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59013acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_id_to_entity_map = {}\n",
    "\n",
    "for i, (text, labels) in enumerate(zip(dev_texts, dev_labels)):\n",
    "    dev_id_to_entity_map[i] = defaultdict(list)\n",
    "    for token, label in zip(text, labels):\n",
    "        if label == \"O\":\n",
    "            continue\n",
    "        prefix, tag = label.split(\"-\")\n",
    "        if prefix == \"B\":\n",
    "            dev_id_to_entity_map[i][tag].append([])\n",
    "            dev_id_to_entity_map[i][tag][-1].append(label)\n",
    "        elif prefix == \"I\":\n",
    "            dev_id_to_entity_map[i][tag][-1].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeb5e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['специальный', 'агент', 'секретной', 'службы', 'сша', 'джеззи', 'фланниган', ',', 'ответственная', 'за', 'нарушение', 'безопасности', ',', 'объединяется', 'с', 'кроссом', ',', 'чтобы', 'найти', 'пропавшую', 'девушку', '.'] ['O', 'O', 'B-GRP', 'I-GRP', 'I-GRP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "ind = 2\n",
    "print(dev_texts[ind], dev_labels[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67dda9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'GRP': [['B-GRP', 'I-GRP', 'I-GRP']]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_id_to_entity_map[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca29f5",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e1906d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(SAVE_PATH, local_files_only=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15c80467",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained, local_files_only=False)\n",
    "max_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55a822dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(text, model=model):\n",
    "    tokenized = torch.LongTensor([\n",
    "        tokenizer.encode(text, max_length=max_len, padding=\"max_length\", truncation=True)\n",
    "    ]).to(device)\n",
    "    out = model(tokenized).logits\n",
    "    out = torch.argmax(out, dim=2)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8de786da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (800 of 800) |######################| Elapsed Time: 0:13:23 Time:  0:13:23\n"
     ]
    }
   ],
   "source": [
    "dev_x = [item[0] for item in dev_data]\n",
    "dev_y_true = [item[1] for item in dev_data]\n",
    "dev_y_pred = [get_pred(item) for item in pb(dev_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92c9f732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('выпущен 15 февраля 2019 года лейблом mtv .',\n",
       " 'выпущен 15 февраля 2019 года леиблом mtv.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 7\n",
    "dev_y_true[ind], dev_y_pred[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e999c",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab484d",
   "metadata": {},
   "source": [
    "### Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b42832f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idx = [7, 107, 223, 654]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffdf8ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: выпущен 15 февраля 2019 года лейблом mtv .\n",
      "Pred: выпущен 15 февраля 2019 года леиблом mtv.\n",
      "\n",
      "True: в 1968 — 1969 годах играл за команду класса « б » колхоз .\n",
      "Pred: в 1968 — 1969 годах играл за команду класса « б » колхоз\n",
      "\n",
      "True: сан педро де атакама ( ) — посёлок в париж .\n",
      "Pred: сан педро де ударама ( ) — поселок в париж.\n",
      "\n",
      "True: париж — река во владимирской области россии , приток войнинги .\n",
      "Pred: париж — река во владимирскои области россии, приток воининги.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in good_idx:\n",
    "    print(f\"True: {dev_y_true[idx]}\")\n",
    "    print(f\"Pred: {dev_y_pred[idx]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbad024",
   "metadata": {},
   "source": [
    "### Bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6246ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx = [22, 780, 2, 674]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df001c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: по собственному признанию есть три сми , которые тиган ценит с профессиональной точки зрения : mtv , колхоз , and колхоз .\n",
      "Pred: по собственному признанию есть три сми, которые тиган ценил с профессиональнои точки зрения : mtv, сингл\n",
      "\n",
      "True: dvd сверху красновато коричневая , по бокам более светлая .\n",
      "Pred: dvdd красновато коричневая по по по более светлая.\n",
      "\n",
      "True: специальный агент колхоз джеззи фланниган , ответственная за нарушение безопасности , объединяется с кроссом , чтобы найти пропавшую девушку .\n",
      "Pred: специальныи сингл секретно за за за за, за за за засяся,,,,м,,вшую..\n",
      "\n",
      "True: « андрей полисадов » — поэма человек .\n",
      "Pred: « сингл » — поэма анд андрея вознес..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in bad_idx:\n",
    "    print(f\"True: {dev_y_true[idx]}\")\n",
    "    print(f\"Pred: {dev_y_pred[idx]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468db4e3",
   "metadata": {},
   "source": [
    "# Decode predictions and calc metrics (by spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3cbea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_pred(y_true, y_pred):\n",
    "    pred_labels = []\n",
    "\n",
    "    y_pred = y_pred.replace(\"ё\", \"е\").replace(\"й\", \"и\")\n",
    "    y_pred = word_tokenize(y_pred)\n",
    "    \n",
    "    y_true = y_true.replace(\"ё\", \"е\").replace(\"й\", \"и\")\n",
    "    y_true = word_tokenize(y_true)\n",
    "    \n",
    "    true_labels = [word_label2label.get(token, \"O\") for token in y_true]\n",
    "    pred_labels = [word_label2label.get(token, \"O\") for token in y_pred]\n",
    "    \n",
    "    true_len = len(true_labels)\n",
    "    pred_len = len(pred_labels)\n",
    "    \n",
    "    if true_len > pred_len:\n",
    "        pred_labels.extend([\"O\"] * (true_len - pred_len))\n",
    "    elif pred_len > true_len:\n",
    "        true_labels.extend([\"O\"] * (pred_len - true_len))\n",
    "            \n",
    "    assert len(true_labels) == len(pred_labels)\n",
    "    return true_labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a77064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_id_to_entity_map_cp = deepcopy(dev_id_to_entity_map)\n",
    "\n",
    "final_dev_pred = []\n",
    "\n",
    "for i, (t, p, labels) in enumerate(zip(dev_y_true, dev_y_pred, dev_labels)):\n",
    "    t, p  = decode_pred(t, p)\n",
    "    fin = []\n",
    "\n",
    "    for label in p:\n",
    "        if label == \"O\":\n",
    "            fin.append(\"O\")\n",
    "        else:\n",
    "            if label in dev_id_to_entity_map_cp[i]:\n",
    "                fin.extend(dev_id_to_entity_map_cp[i][label][0])\n",
    "                if len(dev_id_to_entity_map_cp[i][label]) > 1:\n",
    "                    dev_id_to_entity_map_cp[i][label] = dev_id_to_entity_map_cp[i][label][1:]\n",
    "            else:\n",
    "                fin.append(\"B-\" + label)\n",
    "    \n",
    "    true_len = len(labels)\n",
    "    pred_len = len(fin)\n",
    "    \n",
    "    if true_len > pred_len:\n",
    "        fin.extend([\"O\"] * (true_len - pred_len))\n",
    "    elif pred_len > true_len:\n",
    "        fin = fin[:true_len]\n",
    "    assert len(fin) == len(labels)\n",
    "    final_dev_pred.append(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b7dabef9-513e-49fd-960a-cbdfdbed21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(labels):\n",
    "    fin_spans = []\n",
    "    for item_ in labels:\n",
    "        item = deepcopy(item_)\n",
    "        item.insert(0, \"O\")\n",
    "        item.append(\"O\")\n",
    "\n",
    "        new_spans = {}\n",
    "        for i, label in enumerate(item[1:-1], 1):\n",
    "\n",
    "            if item[i] == \"O\":\n",
    "                new_spans[(i-1, i-1)] = \"O\"\n",
    "            else:\n",
    "                if item[i-1] == 'O':\n",
    "                    start_i = i\n",
    "                if item[i+1] == 'O':\n",
    "                    new_spans[(start_i-1, i-1)] = item[i].split('-')[1]\n",
    "                    \n",
    "        fin_spans.append(new_spans)\n",
    "                \n",
    "    return fin_spans    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8cf73f0b-1dba-47ca-8aaf-8284b04c0d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_spans = get_spans(dev_labels)\n",
    "pred_spans = get_spans(final_dev_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "42f79dba-6e64-4746-a5c5-8712cd14b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_f1(pred_spans, true_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7d9e4e5f-5027-4ebd-8798-5739587f01ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P@CORP': 0.758333333333333,\n",
       " 'R@CORP': 0.5833333333333331,\n",
       " 'F1@CORP': 0.6594202898550231,\n",
       " 'P@PROD': 0.7684210526315784,\n",
       " 'R@PROD': 0.48666666666666647,\n",
       " 'F1@PROD': 0.595918367346891,\n",
       " 'P@CW': 0.527950310559006,\n",
       " 'R@CW': 0.5120481927710842,\n",
       " 'F1@CW': 0.5198776758409284,\n",
       " 'P@PER': 0.5962732919254656,\n",
       " 'R@PER': 0.49999999999999983,\n",
       " 'F1@PER': 0.5439093484418766,\n",
       " 'P@LOC': 0.6687499999999997,\n",
       " 'R@LOC': 0.4908256880733944,\n",
       " 'F1@LOC': 0.5661375661375172,\n",
       " 'P@GRP': 0.7317073170731703,\n",
       " 'R@GRP': 0.39999999999999986,\n",
       " 'F1@GRP': 0.5172413793102989,\n",
       " 'micro@P': 0.6572528883183568,\n",
       " 'micro@R': 0.49612403100775193,\n",
       " 'micro@F1': 0.5654334621755446,\n",
       " 'MD@R': 0.5135658914728682,\n",
       " 'MD@P': 0.6803594351732991,\n",
       " 'MD@F1': 0.5853119823301554,\n",
       " 'ALLTRUE': 2064,\n",
       " 'ALLRECALLED': 1060,\n",
       " 'ALLPRED': 1558}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_f1.get_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561e87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
