{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23830fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import os, operator\n",
    "from progressbar import progressbar as pb\n",
    "from nltk import word_tokenize\n",
    "from typing import List, Tuple\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "import gdown #! pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9611a294-364c-40b3-ba84-b534421edca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-4fS0lwbS1fZcGmlOn2ro81X68zkQ8ZX\n",
      "To: /Users/alex/Python/multiconer/my_experiments/models/template_free/sbert_large_nlu_ru.zip\n",
      "100%|██████████████████████████████████████| 1.59G/1.59G [02:24<00:00, 11.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "! gdown https://drive.google.com/uc?id=1-4fS0lwbS1fZcGmlOn2ro81X68zkQ8ZX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b66cf92-06fa-47ad-8c8c-e8b14a08b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  sbert_large_nlu_ru.zip\n",
      "   creating: sbert_large_nlu_ru/\n",
      "  inflating: sbert_large_nlu_ru/.DS_Store  \n",
      "  inflating: __MACOSX/sbert_large_nlu_ru/._.DS_Store  \n",
      "  inflating: sbert_large_nlu_ru/config.json  \n",
      "  inflating: __MACOSX/sbert_large_nlu_ru/._config.json  \n",
      "  inflating: sbert_large_nlu_ru/pytorch_model.bin  \n",
      "  inflating: __MACOSX/sbert_large_nlu_ru/._pytorch_model.bin  \n"
     ]
    }
   ],
   "source": [
    "! unzip sbert_large_nlu_ru.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c687efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../../SemEval2022-Task11_Train-Dev/RU-Russian/\"\n",
    "pretrained = \"sberbank-ai/sbert_large_nlu_ru\"\n",
    "SAVE_PATH = \"sbert_large_nlu_ru/\"\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69694c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, \"ru_dev.conll\")) as f:\n",
    "    dev_file = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade3c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conll(file) -> Tuple[List, List]:\n",
    "    texts, labels = [], []\n",
    "    \n",
    "    for row in file:\n",
    "        if row.startswith(\"#\"):\n",
    "            new_texts, new_labels = [], []\n",
    "            continue\n",
    "\n",
    "        if row == \"\":\n",
    "            texts.append(new_texts)\n",
    "            labels.append(new_labels)\n",
    "\n",
    "        else:\n",
    "            parts = row.split()\n",
    "            new_texts.append(parts[0])\n",
    "            new_labels.append(parts[-1])\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "dev_texts, dev_labels = parse_conll(dev_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d403a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10fd734b-7c04-427b-bd27-04442bbc63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2word_label = { # label words dict\n",
    "    \"GRP\": \"колхоз\",\n",
    "    \"PER\": \"человек\",\n",
    "    \"CW\": \"сингл\",\n",
    "    \"PROD\": \"dvd\",\n",
    "    \"CORP\": \"mtv\",\n",
    "    \"LOC\": \"париж\"\n",
    "}\n",
    "\n",
    "word_label2label = {v:k for k, v in label2word_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a904465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_target(tokens, labels, label2word_label=label2word_label):\n",
    "    \"\"\"\n",
    "        Replace entities with label words\n",
    "    \"\"\"\n",
    "    new_tokens = []\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if label.startswith(\"B-\"):\n",
    "            prefix, tag = label.split(\"-\")\n",
    "            new_token = label2word_label[tag]\n",
    "            new_tokens.append(new_token)\n",
    "        elif label.startswith(\"I-\"):\n",
    "            continue\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "    \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9a804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = []\n",
    "    \n",
    "for tokens, label_list in zip(dev_texts, dev_labels):\n",
    "    target = prepare_target(tokens, label_list)\n",
    "    x = \" \".join(tokens)\n",
    "    y = \" \".join(target)\n",
    "    dev_data.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59013acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_id_to_entity_map = {}\n",
    "\n",
    "for i, (text, labels) in enumerate(zip(dev_texts, dev_labels)):\n",
    "    dev_id_to_entity_map[i] = defaultdict(list)\n",
    "    for token, label in zip(text, labels):\n",
    "        if label == \"O\":\n",
    "            continue\n",
    "        prefix, tag = label.split(\"-\")\n",
    "        if prefix == \"B\":\n",
    "            dev_id_to_entity_map[i][tag].append([])\n",
    "            dev_id_to_entity_map[i][tag][-1].append(label)\n",
    "        elif prefix == \"I\":\n",
    "            dev_id_to_entity_map[i][tag][-1].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb5e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['специальный', 'агент', 'секретной', 'службы', 'сша', 'джеззи', 'фланниган', ',', 'ответственная', 'за', 'нарушение', 'безопасности', ',', 'объединяется', 'с', 'кроссом', ',', 'чтобы', 'найти', 'пропавшую', 'девушку', '.'] ['O', 'O', 'B-GRP', 'I-GRP', 'I-GRP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "ind = 2\n",
    "print(dev_texts[ind], dev_labels[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67dda9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'GRP': [['B-GRP', 'I-GRP', 'I-GRP']]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_id_to_entity_map[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca29f5",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1906d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(SAVE_PATH, local_files_only=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15c80467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da416ce7155c4f828680e88d68a8d98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1780720.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d8e46485f14b8caaea8b2c0877ce74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcdc127d9b342f39dca701eba1b7577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=323.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained, local_files_only=False)\n",
    "max_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a822dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(text, model=model):\n",
    "    tokenized = torch.LongTensor([\n",
    "        tokenizer.encode(text, max_length=max_len, padding=\"max_length\", truncation=True)\n",
    "    ]).to(device)\n",
    "    out = model(tokenized).logits\n",
    "    out = torch.argmax(out, dim=2)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de786da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (800 of 800) |######################| Elapsed Time: 0:12:12 Time:  0:12:12\n"
     ]
    }
   ],
   "source": [
    "dev_x = [item[0] for item in dev_data]\n",
    "dev_y_true = [item[1] for item in dev_data]\n",
    "dev_y_pred = [get_pred(item) for item in pb(dev_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92c9f732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('выпущен 15 февраля 2019 года лейблом mtv .',\n",
       " 'выпущен 15 февраля 2019 года леиблом mtv.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 7\n",
    "dev_y_true[ind], dev_y_pred[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e999c",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab484d",
   "metadata": {},
   "source": [
    "### Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b42832f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idx = [7, 107, 223, 654]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffdf8ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: выпущен 15 февраля 2019 года лейблом mtv .\n",
      "Pred: выпущен 15 февраля 2019 года леиблом mtv.\n",
      "\n",
      "True: в 1968 — 1969 годах играл за команду класса « б » колхоз .\n",
      "Pred: в 1968 — 1969 годах играл за команду класса « б » колхоз\n",
      "\n",
      "True: сан педро де атакама ( ) — посёлок в париж .\n",
      "Pred: сан педро де ударама ( ) — поселок в париж.\n",
      "\n",
      "True: париж — река во владимирской области россии , приток войнинги .\n",
      "Pred: париж — река во владимирскои области россии, приток воининги.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in good_idx:\n",
    "    print(f\"True: {dev_y_true[idx]}\")\n",
    "    print(f\"Pred: {dev_y_pred[idx]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbad024",
   "metadata": {},
   "source": [
    "### Bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6246ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx = [22, 780, 2, 674]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df001c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: по собственному признанию есть три сми , которые тиган ценит с профессиональной точки зрения : mtv , колхоз , and колхоз .\n",
      "Pred: по собственному признанию есть три сми, которые тиган ценил с профессиональнои точки зрения : mtv, сингл\n",
      "\n",
      "True: dvd сверху красновато коричневая , по бокам более светлая .\n",
      "Pred: dvdd красновато коричневая по по по более светлая.\n",
      "\n",
      "True: специальный агент колхоз джеззи фланниган , ответственная за нарушение безопасности , объединяется с кроссом , чтобы найти пропавшую девушку .\n",
      "Pred: специальныи сингл секретно за за за за, за за за засяся,,,,м,,вшую..\n",
      "\n",
      "True: « андрей полисадов » — поэма человек .\n",
      "Pred: « сингл » — поэма анд андрея вознес..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in bad_idx:\n",
    "    print(f\"True: {dev_y_true[idx]}\")\n",
    "    print(f\"Pred: {dev_y_pred[idx]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468db4e3",
   "metadata": {},
   "source": [
    "# Decode predictions and calc metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3cbea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_pred(y_true, y_pred):\n",
    "    pred_labels = []\n",
    "\n",
    "    y_pred = y_pred.replace(\"ё\", \"е\").replace(\"й\", \"и\")\n",
    "    y_pred = word_tokenize(y_pred)\n",
    "    \n",
    "    y_true = y_true.replace(\"ё\", \"е\").replace(\"й\", \"и\")\n",
    "    y_true = word_tokenize(y_true)\n",
    "    \n",
    "    true_labels = [word_label2label.get(token, \"O\") for token in y_true]\n",
    "    pred_labels = [word_label2label.get(token, \"O\") for token in y_pred]\n",
    "    \n",
    "    true_len = len(true_labels)\n",
    "    pred_len = len(pred_labels)\n",
    "    \n",
    "    if true_len > pred_len:\n",
    "        pred_labels.extend([\"O\"] * (true_len - pred_len))\n",
    "    elif pred_len > true_len:\n",
    "        true_labels.extend([\"O\"] * (pred_len - true_len))\n",
    "            \n",
    "    assert len(true_labels) == len(pred_labels)\n",
    "    return true_labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a77064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_id_to_entity_map_cp = deepcopy(dev_id_to_entity_map)\n",
    "\n",
    "final_dev_pred = []\n",
    "\n",
    "for i, (t, p, labels) in enumerate(zip(dev_y_true, dev_y_pred, dev_labels)):\n",
    "    t, p  = decode_pred(t, p)\n",
    "    fin = []\n",
    "\n",
    "    for label in p:\n",
    "        if label == \"O\":\n",
    "            fin.append(\"O\")\n",
    "        else:\n",
    "            if label in dev_id_to_entity_map_cp[i]:\n",
    "                fin.extend(dev_id_to_entity_map_cp[i][label][0])\n",
    "                if len(dev_id_to_entity_map_cp[i][label]) > 1:\n",
    "                    dev_id_to_entity_map_cp[i][label] = dev_id_to_entity_map_cp[i][label][1:]\n",
    "            else:\n",
    "                fin.append(\"B-\" + label)\n",
    "    \n",
    "    true_len = len(labels)\n",
    "    pred_len = len(fin)\n",
    "    \n",
    "    if true_len > pred_len:\n",
    "        fin.extend([\"O\"] * (true_len - pred_len))\n",
    "    elif pred_len > true_len:\n",
    "        fin = fin[:true_len]\n",
    "    assert len(fin) == len(labels)\n",
    "    final_dev_pred.append(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86e20645",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_true = [item for sublist in dev_labels for item in sublist]\n",
    "flat_pred = [item for sublist in final_dev_pred for item in sublist]\n",
    "\n",
    "flat_true = [item.replace(\"I-\", \"\").replace(\"B-\", \"\") for item in flat_true]\n",
    "flat_pred = [item.replace(\"I-\", \"\").replace(\"B-\", \"\") for item in flat_pred]\n",
    "assert len(flat_true) == len(flat_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bc127",
   "metadata": {},
   "source": [
    "### Micro Avg. on all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3165e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "avg = \"micro\"\n",
    "\n",
    "result[\"ALL\"] = {\n",
    "    \"precision\": precision_score(flat_true, flat_pred, average=avg),\n",
    "    \"recall\": recall_score(flat_true, flat_pred, average=avg),\n",
    "    \"f1\": f1_score(flat_true, flat_pred, average=avg)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d88f4d",
   "metadata": {},
   "source": [
    "### By class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3955beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in label2word_label.keys():\n",
    "    precision = precision_score(flat_true, flat_pred, labels=[label], average=avg)\n",
    "    recall = recall_score(flat_true, flat_pred, labels=[label], average=avg)\n",
    "    f1 = f1_score(flat_true, flat_pred, labels=[label], average=avg)\n",
    "    \n",
    "    result[label] = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0ca8ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALL': {'precision': 0.9138471177944862,\n",
       "  'recall': 0.9138471177944862,\n",
       "  'f1': 0.9138471177944862},\n",
       " 'GRP': {'precision': 0.8305084745762712,\n",
       "  'recall': 0.5017064846416383,\n",
       "  'f1': 0.6255319148936169},\n",
       " 'PER': {'precision': 0.7034883720930233,\n",
       "  'recall': 0.6269430051813472,\n",
       "  'f1': 0.663013698630137},\n",
       " 'CW': {'precision': 0.6398809523809523,\n",
       "  'recall': 0.617816091954023,\n",
       "  'f1': 0.6286549707602339},\n",
       " 'PROD': {'precision': 0.776,\n",
       "  'recall': 0.46859903381642515,\n",
       "  'f1': 0.5843373493975903},\n",
       " 'CORP': {'precision': 0.825,\n",
       "  'recall': 0.5913978494623656,\n",
       "  'f1': 0.6889352818371607},\n",
       " 'LOC': {'precision': 0.6988636363636364,\n",
       "  'recall': 0.48616600790513836,\n",
       "  'f1': 0.5734265734265734}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561e87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
